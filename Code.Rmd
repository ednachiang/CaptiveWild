---
title: "Code"
author: "Edna Chiang"
date: "May 7, 2018"
output: html_document
---

### Load Libraries
```{r}
library(ape)
library(dplyr)
library(ggplot2)
library(gplots)
library(phangorn)
library(tidyr)
library(vegan)
library(phyloseq)
library(grid)
library(pgirmess)
theme_set(theme_bw())
set.seed(1)
```

### Load Functions
```{r}
veganCovEllipse <- function(cov, center = c(0, 0), scale = 1, npoints = 100) {
    theta <- (0:npoints) * 2 * pi/npoints
    Circle <- cbind(cos(theta), sin(theta))
    t(center + scale * t(Circle %*% chol(cov)))
}



simper.pretty = function(x, metrics, interesting, perc_cutoff, low_cutoff, low_val, output_name){
  library(vegan)
  #handling otu tables for taxa levels
  save=list(0)
  if(grepl("Otu", colnames(x)[1])!=TRUE){
    #converts output from A.Neumann Taxonomy script
    save=list(58)
    x=as.data.frame(t(x))
    orig_names=colnames(x)
    new_names=list()
    l=1
    for(n in colnames(x)){
      ifelse((l<10), (colnames(x)[l]=c(paste0('Otu000',c(l)))), (colnames(x)[l]=c(paste0('Otu00',c(l)))))
      new_names=append(new_names, colnames(x)[l])
      l=l+1
    }
    orig_names=as.data.frame(orig_names, row.names = as.character(new_names))
  }
  #running simper
  for(variables in interesting){
    test_1=with(metrics, simper(x, metrics[[variables]]))
    #parsing through simper output, saving desired info to table
    for(name in names(test_1)){
      testmx=matrix(ncol=length(interesting))
      testmx=cbind(test_1[[name]]$ord,test_1[[name]]$cusum)
      sorted=testmx[order(testmx[,1]),]
      sorted=cbind(sorted,test_1[[name]]$species)
      sorted=sorted[order(sorted[,2]),]
      t=matrix(sorted[sorted[,2]<=perc_cutoff,],ncol=3)
      i=nrow(t)
      #converting percents to percent of whole
      while(i>1){
        t[i,2]=as.character(as.numeric(t[i,2])-as.numeric(t[i-1,2]))
        i=i-1
      }
      t[,1]=name
      write.table(t,file=paste(output_name,'_simper.csv',sep=""), append=TRUE, sep=",", col.names = FALSE)
    }}
  y=read.table(paste(output_name,'_simper.csv',sep=""), header=FALSE,sep=",",fill = TRUE,row.names = NULL)
  file.remove(paste(output_name,'_simper.csv',sep = ""))
  y=y[-c(1)]
  colnames(y) = c("Comparison", "SIMPER", "OTU")
  #removing results lower than low cutoff
  if(low_cutoff=='y'){
    y=y[!(as.numeric(as.character(y$SIMPER))<low_val),]
  }
  #prevents changing of colnames if OTU table
  if(58 %in% save){
    y$OTU=orig_names[match(y$OTU, rownames(orig_names)),1]
  }
  write.csv(y,file=paste(output_name,'_clean_simper.csv', sep=''))
}



kruskal.pretty = function(otu, metrics, csv, interesting, output_name, taxonomy){
  library(vegan)
  library(dplyr)
  if(grepl("Otu", colnames(otu)[1])!=TRUE){
    #converts output from A.Neuman Taxonomy script
    otu=as.data.frame(t(otu))
  }
  #changing csv$X to rownames to allow proper splitting of comparisons
  csv$X=as.integer(rownames(csv))
  L=list()
  R=list()
  mean_L=c()
  sd_L=c()
  mean_R=c()
  sd_R=c()
  L_mean=c()
  R_mean=c()
  L_sd=c()
  R_sd=c()
  krusk=c()
  tax=c()
  L_abund=c()
  R_abund=c()
  L_abund_sd=c()
  R_abund_sd=c()
  abund=as.matrix(otu)
  abund=abund/rowSums(abund)
  for(b in levels(csv$Comparison)){
    otu_list=dplyr::filter(csv, Comparison==b) #saves otu list for current comparison
    for(i in csv$X){
      if(as.character(csv$Comparison[i])==b){  ##splitting comparisons so can call individually for table generation
        splt=as.data.frame(matrix(unlist(strsplit(as.character(csv$Comparison[i]),'_')), nrow=1, byrow=T))
        cola=as.character(splt[1,1])
        colb=as.character(splt[1,2])
        break
      }
    }
    #saving topic containing var of interest (cola/colb) (less memory intensive)
    for(topic in interesting){
      #preventing crash if there is only one topic in interesting
      if(is.null(levels(metrics[[topic]]))==TRUE){
        topic1=topic
        break
      }
      for(sbtpic in levels(metrics[[topic]])){
        if(sbtpic==cola){
          topic1=topic
          break
        }
      } 
    }
    #iterate thru rows in tpics of intrst til matches cola and colb, generates otu and metrics tbl  ##!Processing can be reduced!##
    for(rowe1 in metrics[[topic1]]){
      for(rowe2 in metrics[[topic1]]){ 
        if(rowe1==cola & rowe2==colb){ 
          listbact=otu[c(metrics[[topic1]]==cola|metrics[[topic1]]==colb),]
          listmet=metrics[c(metrics[[topic1]]==cola|metrics[[topic1]]==colb),]
          break
        }
      }
    }
    #collecting differential abundances
    sample_L=row.names(subset(metrics, metrics[[topic1]] == c(cola)))
    sample_R=row.names(subset(metrics, metrics[[topic1]] == c(colb)))
    #collecting abund values, perform/save mean and stdev calculations
    for(otus in otu_list$OTU){
      for(sample in sample_L){
        L=append(L,abund[sample,otus])
        mean_L[[otus]]=mean(as.numeric(L))
        sd_L[[otus]]=sd(as.numeric(L))
      }
      for(sample in sample_R){
        R=append(R,abund[sample,otus])
        mean_R[[otus]]=mean(as.numeric(R))
        sd_R[[otus]]=sd(as.numeric(R))
      }
      L=list()
      R=list()
    }
    #runs kruskal.test for each otu in simper csv, stores as list, also stores abundances
    for(otus in otu_list$OTU){
      result=kruskal.test(listbact[[otus]]~listmet[[topic1]])
      krusk=append(krusk, result$p.value)
      #stores taxonomic classification for each otu as list
      if(missing(taxonomy)){
        tax=append(tax, c("NA"))
      } else {
        tax=append(tax, as.character(taxonomy[otus, "Taxonomy"]))
      }
      L_mean=append(L_mean, as.character(mean_L[[otus]]))
      R_mean=append(R_mean, as.character(mean_R[[otus]]))
      L_sd=append(L_sd, as.character(sd_L[[otus]]))
      R_sd=append(R_sd, as.character(sd_R[[otus]]))
      
    }
  }
  #adjusted p-values for multiple comparisons
  fdr=p.adjust(krusk, method='fdr')
  #order csv to match 'krusk'/'fdr' list, add p.val, add taxonomy, re-ord to match orig csv, write to csv
  o_csv=dplyr::arrange(csv, Comparison)
  o_csv[,5]=krusk
  o_csv[,6]=fdr
  o_csv[,7]=tax
  o_csv[,8]=L_mean
  o_csv[,9]=L_sd
  o_csv[,10]=R_mean
  o_csv[,11]=R_sd
  o_csv=dplyr::arrange(o_csv, X)
  colnames(o_csv)[which(names(o_csv) == "V5")] <- "krusk_p.val" #changes column header
  colnames(o_csv)[which(names(o_csv) == "V6")] <- "fdr_krusk_p.val"
  colnames(o_csv)[which(names(o_csv) == "V7")] <- "Taxonomy"
  colnames(o_csv)[which(names(o_csv) == "V8")] <- "Left mean abund"
  colnames(o_csv)[which(names(o_csv) == "V9")] <- "Left stdev"
  colnames(o_csv)[which(names(o_csv) == "V10")] <- "Right mean abund"
  colnames(o_csv)[which(names(o_csv) == "V11")] <- "Right stdev"
  o_csv[,1]=NULL
  write.csv(o_csv, file=paste(output_name,"_krusk_simper.csv", sep=""))
}
```

### Import Data
```{r}
# Link files
shared = "mothur_output/final.shared"
taxonomy = "mothur_output/final.taxonomy"


# Import mothur data
mothurdata = import_mothur(
  mothur_shared_file = shared,
  mothur_constaxonomy_file = taxonomy)

# Add OTU column in taxonomy table
tax_table(mothurdata) <- cbind(tax_table(mothurdata), 
                               row.names(tax_table(mothurdata)))

# Rename taxonomy table columns
colnames(tax_table(mothurdata)) <- 
  c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus", "Species")
```

### Explore mothurdata object
```{r}
samp.sum <- data.frame(colSums(otu_table(mothurdata)))
colnames(samp.sum) <- "Sample_TotalSeqs"
samp.sum$sample <- row.names(samp.sum)
samp.sum <- arrange(samp.sum, Sample_TotalSeqs)

ggplot(samp.sum, aes(x=reorder(sample, Sample_TotalSeqs), y=Sample_TotalSeqs)) +
  ylab("Number of Sequences per Sample") +
  geom_bar(stat="identity", colour="black", fill="cornflowerblue") +
  xlab("Sample Name") +
  ggtitle("Total Number of Sequences per Sample") + 
  theme(axis.text.x = element_text(colour = "black", size=6, angle=45,hjust = 1,
                                   vjust = 1))

ggplot(data.frame(sum = sample_sums(mothurdata)), aes(sum)) + 
  geom_histogram(colour = "white", fill = "blue", bins=60) + 
  ggtitle("Sample read counts") + 
  xlab("total sequences")


# Min, Mean, Max of sample read counts
min(sample_sums(mothurdata))
mean(sample_sums(mothurdata))
median(sample_sums(mothurdata))
max(sample_sums(mothurdata))
```


### Interim Phyloseq Object
```{r}
meta <- read.csv("metadata.csv")
colnames(meta)[1] <- "Sample"
rownames(meta) <- meta$Sample
divsum <- read.table("mothur_output/8494.summary", header=T)
remove <- setdiff(meta$Sample, divsum$group)
for(i in 1:length(remove)){
  meta <- meta[-which(meta$Sample == remove[i]),]
}


# Add in diversity summaries
meta[,11:21] <- divsum[,3:12]

# Create intermin phyloseq object
physeq <- merge_phyloseq(mothurdata, sample_data(meta))

# Order factors
sample_data(physeq)$Season <- ordered(sample_data(physeq)$Season,
                                     levels=c("Summer", "Winter", "Spring"))
sample_data(physeq)$Metabolism <- ordered(sample_data(physeq)$Metabolism,
                                     levels=c("Active", "Torpor", "IBA"))
sample_data(physeq)$Group <- ordered(sample_data(physeq)$Group,
                                     levels=c("Summer_Wild", "Summer_Lab", "Torpor", "IBA", "Spring", "Chow"))

# Remove unwanted samples
physeq.rem <- subset_samples(physeq, Sample_Type != "Black_Tissue" & Season != "NA")



#save(physeq.rem, file="Physeq.RData")
```
### Chow
```{r}
physeq.chow <- subset_samples(physeq, Sample_Type == "Chow")
chow.phy <- tax_glom(physeq.chow, taxrank="Phylum")
chow.phy99 <- transform_sample_counts(chow.phy, function(x){(x/sum(x))*100})
chow.phy99 <- prune_taxa(taxa_sums(chow.phy99) > 1, chow.phy99)

barplot(sort(taxa_sums(chow.phy99),TRUE)[1:20],las=2,cex.axis=.7)

chow.df <- psmelt(chow.phy99)
chow.df$Phylum <- ordered(chow.df$Phylum, levels=c("Proteobacteria", "Firmicutes", "Bacteroidetes", "Actinobacteria"))

tiff("Chow.tiff", width=5, height=5, units="in", res=600)
ggplot(chow.df, aes(x=Phylum, y=Abundance, fill=Phylum)) +
  geom_bar(stat="identity", color="black") +
  scale_fill_manual(values=c("#984ea3", "#e41a1c", "#377eb8", "#f781bf")) +
  xlab("Phyla") +
  ylab("Relative Abundance for Phyla > 1%") +
  scale_y_continuous(limits=c(0,65),expand=c(0,0)) +
  theme(axis.text.x = element_blank(),
        axis.title.x = element_text(size=14),
        axis.title.y = element_text(size=14),
        strip.text.x = element_text(size=12),
        strip.text.y = element_text(size=12),
        panel.spacing=unit(1, "lines"))
dev.off()

##### Alpha Div
physeq.wchow <- subset_samples(physeq, Sample_Type != "Black_Tissue")
chow.adiv <- data.frame(sample_data(physeq.wchow))
chow.adiv.sum <- chow.adiv %>%
  group_by(Group) %>%
  summarize(Chao_Mean = mean(chao),
            Chao_Median = median(chao),
            Chao_SD = sd(chao),
            Chao_SE = (sd(chao)/sqrt(length(chao))),
            Chao_iqr = IQR(chao),
            InvSimp_Mean = mean(invsimpson),
            InvSimp_Median = median(invsimpson),
            InvSimp_SD = sd(invsimpson),
            InvSimp_SE = (sd(invsimpson)/sqrt(length(invsimpson))),
            InvSimp_iqr = IQR(invsimpson))
tiff("Chow.chao.tiff", width=7, height=3, units="in", res=600)
ggplot(chow.adiv, aes(x=Group, y=chao, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  #facet_grid(.~Substrate) +
  scale_fill_manual(values=c("brown2", "lightcoral", "royalblue3", "deepskyblue", "limegreen", "gray26")) +
  #scale_fill_manual(values=c("gray95", "dimgray") )+
  xlab("Group") +
  ylab("Chao Richness")
dev.off()

tiff("Chow.InvSimp.tiff", width=7, height=3, units="in", res=600)
ggplot(chow.adiv, aes(x=Group, y= invsimpson, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  #facet_grid(.~Substrate) +
  scale_fill_manual(values=c("brown2", "lightcoral", "royalblue3", "deepskyblue", "limegreen", "gray26")) +
  xlab("Group") +
  ylab("Inverse Simpson Weighted Diversity")
dev.off()
```

### Load Phyloseq Object
```{r}
load("Physeq.RData")
```

### Examine Summer Lab vs. Wild
```{r}
sum.physeq <- subset_samples(physeq.rem, Season == "Summer")

###### Examine Phyla ######
# Merge samples with the same taxonomic rank
sum.goodphy <- tax_glom(sum.physeq, taxrank="Phylum")

# Transform each merged phylum count to rel abund
sum.phy99 <- transform_sample_counts(sum.goodphy, function(x){(x/sum(x))*100})

# Remove any phyla with <1% rel abund
sum.phy99 <- prune_taxa(taxa_sums(sum.phy99) > 1, sum.phy99)


# Summarize data
sum.phy.df <- psmelt(sum.phy99)
sum.phy.df$Phylum <- ordered(sum.phy.df$Phylum, levels=c("Firmicutes", "Bacteroidetes","Verrucomicrobia", "Proteobacteria", "Unclassified", "Cyanobacteria", "Tenericutes", "Elusimicrobia"))
sum.phy.df$Phylum[which(is.na(sum.phy.df$Phylum))] <- rep("Unclassified",18)
sum.phy.sum <- sum.phy.df %>%
  group_by(Diet, Sample_Type, Phylum) %>%
  summarize(Mean = mean(Abundance),
            Median = median(Abundance),
            SD = sd(Abundance),
            SE = (sd(Abundance)/(sqrt(length(Abundance)))),
            iqr = IQR(Abundance))

# Calculate IQR limits
sum.phy.sum$iqr.min <- sum.phy.sum$Median - 0.5*sum.phy.sum$iqr
sum.phy.sum[which(sum.phy.sum$iqr.min < 0),10] <- 0
  # Any IQR min < 0, change to 0 (otherwise error bar won't plot)
sum.phy.sum$iqr.max <- sum.phy.sum$Median + 0.5*sum.phy.sum$iqr


### Barplot ###
ggplot(sum.phy.sum, aes(x=Phylum, y=Median, fill=Phylum)) +
  geom_bar(stat="identity", color="black") +
  geom_errorbar(aes(ymax=iqr.max, ymin=iqr.min), width=0.25) +
  facet_grid(Diet ~ Sample_Type) +
  scale_fill_brewer(palette="Set1") +
  xlab("Phyla") +
  ylab("Median Relative Abundance for Phyla > 1%") +
  theme(axis.text.x = element_blank())


###### Alpha-Diversity ######
sum.adiv <- data.frame(sample_data(sum.physeq))

sum.adiv.con <- sum.adiv[which(sum.adiv$Sample_Type=="Content"),]
sum.adiv.muc <- sum.adiv[which(sum.adiv$Sample_Type=="Mucosa"),]
sum.adiv.lab <- sum.adiv[which(sum.adiv$Diet=="Lab"),]
sum.adiv.wil <- sum.adiv[which(sum.adiv$Diet=="Wild"),]

# Total OTUs
# Make the original, unnormalized phyloseq object

sum.otu.tot <- data.frame(sample_names(sum.physeq))
# Pull out # of OTUs from all samples
sum.otu.tot$Total_OTUs <- rep("NA", 17)
for(i in 1:17){
  sum.otu.tot[i,2] <- length(which(otu_table(sum.physeq)[,i] != 0))
}
colnames(sum.otu.tot) <- c("Sample", "Total_OTUs")
sum.otu.tot$Total_OTUs <- as.integer(sum.otu.tot$Total_OTUs)
sum.otusum <- sum.adiv
sum.otusum$Total_OTUs <- sum.otu.tot$Total_OTUs

# Color by group
ggplot(sum.otusum, aes(x=Diet, y=Total_OTUs, fill = Diet)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  scale_fill_manual(values=c("brown2", "lightcoral")) +
  xlab("Group") +
  ylab("Total OTUs")

# Test normality
hist(sum.otusum$Total_OTUs, breaks=10)
qqnorm(sum.otusum$Total_OTUs)
qqline(sum.otusum$Total_OTUs)
shapiro.test(sum.otusum$Total_OTUs)
  # p-value = 0.0071
  # Not normal
ks.test(sum.otusum$Total_OTUs, "pnorm", mean=mean(sum.otusum$Total_OTUs), sd=sd(sum.otusum$Total_OTUs))
  # p-value = 0.1352

# Wilcoxon
wilcox.test(Total_OTUs ~ Diet, data=sum.otusum)
  # p-value = 0.0001616
wilcox.test(Total_OTUs ~ Diet, data=sum.otusum, subset=Sample_Type=="Content")
  # p-value = 0.01667
wilcox.test(Total_OTUs ~ Diet, data=sum.otusum, subset=Sample_Type=="Mucosa")
  # p-value = 0.05714
wilcox.test(Total_OTUs ~ Sample_Type, data=sum.otusum)
  # p-value = 0.8868
wilcox.test(Total_OTUs ~ Sample_Type, data=sum.otusum, subset=Diet=="Lab")
  # p-value = 0.7879
wilcox.test(Total_OTUs ~ Sample_Type, data=sum.otusum, subset=Diet=="Wild")
  # p-value = 1




### Chao
ggplot(sum.adiv, aes(x=Diet, y=chao, fill = Diet)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  scale_fill_manual(values=c("brown2", "lightcoral") )+
  xlab("Diet") +
  ylab("Chao Richness")

# Test normality
hist(sum.adiv$chao, breaks=10)
qqnorm(sum.adiv$chao)
qqline(sum.adiv$chao)
shapiro.test(sum.adiv$chao)
  # p-value = 0.01554
  # Not normal
ks.test(sum.adiv$chao, "pnorm", mean=mean(sum.adiv$chao), sd=sd(sum.adiv$chao))
  # p-value = 0.6185

# Wilcoxon
wilcox.test(chao ~ Diet, data=sum.adiv)
  # p-value = 0.0202
wilcox.test(chao ~ Diet, data=sum.adiv, subset=Sample_Type=="Content")
  # p-value = 0.01667
wilcox.test(chao ~ Diet, data=sum.adiv, subset=Sample_Type=="Mucosa")
  # p-value = 0.8571
wilcox.test(chao ~ Sample_Type, data=sum.adiv)
  # p-value = 0.9623
wilcox.test(chao ~ Sample_Type, data=sum.adiv, subset=Diet=="Lab")
  # p-value = 0.7879
wilcox.test(chao ~ Sample_Type, data=sum.adiv, subset=Diet=="Wild")
  # p-value = 0.4






### Berger-Parker
ggplot(sum.adiv, aes(x=Diet, y=bergerparker, fill = Diet)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  scale_fill_manual(values=c("brown2", "lightcoral") )+
  xlab("Diet") +
  ylab("Berger-Parker")

# Test normality
hist(sum.adiv$bergerparker, breaks=10)
qqnorm(sum.adiv$bergerparker)
qqline(sum.adiv$bergerparker)
shapiro.test(sum.adiv$bergerparker)
  # p-value = 0.008697
ks.test(sum.adiv$bergerparker, "pnorm", mean=mean(sum.adiv$bergerparker), sd=sd(sum.adiv$bergerparker))
  # p-value = 0.4016

# Wilcoxon
wilcox.test(bergerparker ~ Diet, data=sum.adiv)
  # p-value = 0.149
wilcox.test(bergerparker ~ Diet, data=sum.adiv, subset=Sample_Type=="Content")
  # p-value = 0.03333
wilcox.test(bergerparker ~ Diet, data=sum.adiv, subset=Sample_Type=="Mucosa")
  # p-value = 0.8571
wilcox.test(bergerparker ~ Sample_Type, data=sum.adiv)
  # p-value = 0.9623
wilcox.test(bergerparker ~ Sample_Type, data=sum.adiv, subset=Diet=="Lab")
  # p-value = 0.6485
wilcox.test(bergerparker ~ Sample_Type, data=sum.adiv, subset=Diet=="Wild")
  # p-value = 0.4





### Shannon
ggplot(sum.adiv, aes(x=Diet, y=shannon, fill = Diet)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  scale_fill_manual(values=c("brown2", "lightcoral")) +
  xlab("Group") +
  ylab("Shannon Diversity")

# Test normality
hist(sum.adiv$shannon, breaks=10)
qqnorm(sum.adiv$shannon)
qqline(sum.adiv$shannon)
shapiro.test(sum.adiv$shannon)
  # p-value = 0.2649
ks.test(sum.adiv$shannon, "pnorm", mean=mean(sum.adiv$shannon), sd=sd(sum.adiv$shannon))
  # p-value = 0.6198

# Wilcoxon
t.test(shannon ~ Diet, data=sum.adiv)
  # p-value = 0.05814
t.test(shannon ~ Diet, data=sum.adiv.con)
  # p-value = 0.003129
t.test(shannon ~ Diet, data=sum.adiv.muc)
  # p-value = 0.9498
t.test(shannon ~ Sample_Type, data=sum.adiv)
  # p-value = 0.9695
t.test(shannon ~ Sample_Type, data=sum.adiv.lab)
  # p-value = 0.3654
t.test(shannon ~ Sample_Type, data=sum.adiv.wil)
  # p-value = 0.1508

# Inverse Simpson
ggplot(sum.adiv, aes(x=Diet, y= invsimpson, fill = Diet)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  scale_fill_manual(values=c("brown2", "lightcoral")) +
  xlab("Diet") +
  ylab("Inverse Simpson Diversity")

# Test normality
hist(sum.adiv$invsimpson, breaks=10)
qqnorm(sum.adiv$invsimpson)
qqline(sum.adiv$invsimpson)
shapiro.test(sum.adiv$invsimpson)
  # p-value = 0.01727
ks.test(sum.adiv$invsimpson, "pnorm", mean=mean(sum.adiv$invsimpson), sd=sd(sum.adiv$invsimpson))
  # p-value = 0.2989

# Wilcoxon
wilcox.test(invsimpson ~ Diet, data=sum.adiv)
  # p-value = 0.09825
wilcox.test(invsimpson ~ Diet, data=sum.adiv, subset=Sample_Type=="Content")
  # p-value = 0.01667
wilcox.test(invsimpson ~ Diet, data=sum.adiv, subset=Sample_Type=="Mucosa")
  # p-value = 0.8571
wilcox.test(invsimpson ~ Sample_Type, data=sum.adiv)
  # p-value = 0.8125
wilcox.test(invsimpson ~ Sample_Type, data=sum.adiv, subset=Diet=="Lab")
  # p-value = 0.6485
wilcox.test(invsimpson ~ Sample_Type, data=sum.adiv, subset=Diet=="Wild")
  # p-value = 0.2


###### Bray-Curtis ######
### Bray NMDS
sum.nmds <- ordinate(physeq=sum.physeq, method="NMDS", distance="bray")
  # stress = 0.07623348

plot_ordination(physeq=sum.physeq, ordination=sum.nmds, color="Diet", shape="Sample_Type")

# https://stackoverflow.com/questions/13794419/plotting-ordiellipse-function-from-vegan-package-onto-nmds-plot-created-in-ggplo

sample_data(sum.physeq)$Elip <- paste(sample_data(sum.physeq)$Diet, sample_data(sum.physeq)$Sample_Type)
elip.sum.nmds <- data.frame(MDS1 = sum.nmds$points[,1], MDS2 = sum.nmds$points[,2],
                        Group = sample_data(sum.physeq)$Elip)
plot.new()
elip.sum.ord <- ordiellipse(sum.nmds, sample_data(sum.physeq)$Elip, display="sites", kind="se", conf=0.95, label=T)

veganCovEllipse <- function(cov, center = c(0, 0), scale = 1, npoints = 100) {
    theta <- (0:npoints) * 2 * pi/npoints
    Circle <- cbind(cos(theta), sin(theta))
    t(center + scale * t(Circle %*% chol(cov)))
}

elip.sum.df <- data.frame()
for(i in levels(elip.sum.nmds$Group)){
  elip.sum.df <- rbind(elip.sum.df, cbind(as.data.frame(with(elip.sum.nmds[elip.sum.nmds$Group==i,],
                                                     veganCovEllipse(elip.sum.ord[[i]]$cov,
                                                                     elip.sum.ord[[i]]$center,
                                                                     elip.sum.ord[[i]]$scale))),
                                  group=i))
  
}




plot_ordination(physeq=sum.physeq, ordination=sum.nmds, color="Elip") +
  geom_path(data=elip.sum.df, aes(x=NMDS1, y=NMDS2, colour=group), size=1, linetype=1) +
  guides(color=guide_legend(title="Group")) +
  scale_color_manual(values=c("darkgoldenrod", "darkgoldenrod1", "brown2", "lightcoral"))



### PERMANOVA
sum.sampdf <- data.frame(sample_data(sum.physeq))
sum.bray<- phyloseq::distance(physeq=sum.physeq, method="bray")
adonis(sum.bray~ Diet, data=sum.sampdf)
  # p-value = 0.001
beta.tax = betadisper(d=sum.bray, group=sum.sampdf$Diet)
p <- permutest(beta.tax)
p$tab
  # p-value = 0.002
adonis(sum.bray~ Sample_Type, data=sum.sampdf)
  # p-value = 0.996
beta.tax = betadisper(d=sum.bray, group=sum.sampdf$Sample_Type)
p <- permutest(beta.tax)
p$tab
  # p-value = 0.656
```


### Alpha Div
```{r}
adiv <- data.frame(sample_data(physeq.rem))


# Coverage
ggplot(adiv, aes(x=Group, y= coverage, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  scale_fill_manual(values=c("brown2", "lightcoral", "royalblue3", "deepskyblue", "limegreen")) +
  xlab("Group") +
  ylab("Coverage")

# Total OTUs
# Make the original, unnormalized phyloseq object
shared = "mothur_output/final.shared"
taxonomy = "mothur_output/final.taxonomy"
mothurdata = import_mothur(
  mothur_shared_file = shared,
  mothur_constaxonomy_file = taxonomy)
tax_table(mothurdata) <- cbind(tax_table(mothurdata), 
                               row.names(tax_table(mothurdata)))
colnames(tax_table(mothurdata)) <- 
  c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus", "Species")
# Read in metadata
meta <- read.csv("metadata.csv")
colnames(meta)[1] <- "Sample"
otu.tot <- data.frame(sample_names(mothurdata))
# Pull out # of OTUs from all samples
otu.tot$Total_OTUs <- rep("NA", 77)
for(i in 1:77){
  otu.tot[i,2] <- length(which(otu_table(mothurdata)[,i] != 0))
}
# Pull out the data from just the samples we kept
keep <- data.frame(rep("NA",47))
keep[,2] <- rep("NA", 47)
for(i in 1:47){
  x <- which(otu.tot$sample_names.mothurdata. == sample_names(physeq.rem)[i])
  keep[i,2] <- otu.tot[x,2]
}
keep[,1] <- sample_names(physeq.rem)
colnames(keep) <- c("Sample", "Total_OTUs")
keep$Total_OTUs <- as.integer(keep$Total_OTUs)
adiv$Total_OTUs <- keep$Total_OTUs

# Color by group
tiff("Total_OTUs.tiff", width=6.5, height=3.5, units="in", res=600)
ggplot(adiv, aes(x=Group, y=Total_OTUs, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  #facet_grid(.~Sample_Type) +
  scale_fill_manual(values=c("brown2", "lightcoral", "royalblue3", "deepskyblue", "limegreen")) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Group") +
  ylab("Total OTUs")
dev.off()

# Color by group, facet by sample type
#tiff("Total_OTUs.tiff", width=11, height=3.5, units="in", res=600)
ggplot(adiv, aes(x=Group, y=Total_OTUs, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  scale_fill_manual(values=c("brown2", "lightcoral", "royalblue3", "deepskyblue", "limegreen")) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Group") +
  ylab("Total OTUs")
#dev.off()

# Color by sample type, facet by group
ggplot(adiv, aes(x=Sample_Type, y=Total_OTUs, fill = Sample_Type)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Group) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Sample Type") +
  ylab("Total OTUs")

# Test normality
hist(otusum$Total_OTUs, breaks=10)
qqnorm(otusum$Total_OTUs)
qqline(otusum$Total_OTUs)
shapiro.test(otusum$Total_OTUs)
  # p-value = 1.276e-06
  # p-value = 3.505e-07
ks.test(otusum$Total_OTUs, "pnorm", mean=mean(otusum$Total_OTUs), sd=sd(otusum$Total_OTUs))
  # p-value = 0.01574
  # p-value = 0.0112

# Kruskal-Wallis
kruskal.test(formula = Total_OTUs ~ Group, data = otusum)
  # p-value = 7.987e-05
  # p-value = 8.832e-06
kruskalmc(resp = Total_OTUs ~ Group, data = otusum)
  # Significant:
    # Summer_Wild-Torpor
    # Summer_Wild-IBA
    # Summer_Lab-IBA
kruskal.test(formula = Total_OTUs ~ Group, data = otusum, subset=Diet=="Lab")
  # p-value = 0.004659
  # p-value = 0.004648
kruskal.test(formula = Total_OTUs ~ Sample_Type, data = otusum)
  # p-value = 0.4302
  # p-value = 0.4259
kruskal.test(formula = Total_OTUs ~ Diet, data = otusum)
  # p-value = 8.811e-05
  # p-value = 9.359e-05
kruskal.test(formula = Total_OTUs ~ Diet, data = otusum, subset=Season=="Summer")
  # p-value = 0.009111
wilcox.test(Total_OTUs ~ Diet, data=otusum)
  # p-value = 0.0001003


### Summarize adiv
adiv.sum <- adiv %>%
  group_by(Group) %>%
  summarize(TotalOTUs_Mean = mean(Total_OTUs),
            TotalOTUs_Median = median(Total_OTUs),
            TotalOTUs_SD = sd(Total_OTUs),
            TotalOTUs_SE = (sd(Total_OTUs)/sqrt(length(Total_OTUs))),
            TotalOTUs_iqr = IQR(Total_OTUs),
            Chao_Mean = mean(chao),
            Chao_Median = median(chao),
            Chao_SD = sd(chao),
            Chao_SE = (sd(chao)/sqrt(length(chao))),
            Chao_iqr = IQR(chao),
            Shannon_Mean = mean(shannon),
            Shannon_Median = median(shannon),
            Shannon_SD = sd(shannon),
            Shannon_SE = (sd(shannon)/sqrt(length(shannon))),
            Shannon_iqr = IQR(shannon),
            InvSimp_Mean = mean(invsimpson),
            InvSimp_Median = median(invsimpson),
            InvSimp_SD = sd(invsimpson),
            InvSimp_SE = (sd(invsimpson)/sqrt(length(invsimpson))),
            InvSimp_iqr = IQR(invsimpson))


adiv.samptype.sum <- adiv %>%
  group_by(Group, Sample_Type) %>%
  summarize(TotalOTUs_Mean = mean(Total_OTUs),
            TotalOTUs_Median = median(Total_OTUs),
            TotalOTUs_SD = sd(Total_OTUs),
            TotalOTUs_SE = (sd(Total_OTUs)/sqrt(length(Total_OTUs))),
            TotalOTUs_iqr = IQR(Total_OTUs),
            Chao_Mean = mean(chao),
            Chao_Median = median(chao),
            Chao_SD = sd(chao),
            Chao_SE = (sd(chao)/sqrt(length(chao))),
            Chao_iqr = IQR(chao),
            Shannon_Mean = mean(shannon),
            Shannon_Median = median(shannon),
            Shannon_SD = sd(shannon),
            Shannon_SE = (sd(shannon)/sqrt(length(shannon))),
            Shannon_iqr = IQR(shannon),
            InvSimp_Mean = mean(invsimpson),
            InvSimp_Median = median(invsimpson),
            InvSimp_SD = sd(invsimpson),
            InvSimp_SE = (sd(invsimpson)/sqrt(length(invsimpson))),
            InvSimp_iqr = IQR(invsimpson))





### Chao
# Color by group
tiff("Chao.tiff", width=6.5, height=3, units="in", res=600)
ggplot(adiv, aes(x=Group, y=chao, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  #facet_grid(.~Substrate) +
  scale_fill_manual(values=c("brown2", "lightcoral", "royalblue3", "deepskyblue", "limegreen")) +
  #scale_fill_manual(values=c("gray95", "dimgray") )+
  xlab("Group") +
  ylab("Chao Richness")
dev.off()
# Color by group, facet by sample type
tiff("Chao.facet.tiff", width=11, height=3.5, units="in", res=600)
ggplot(adiv, aes(x=Group, y=chao, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  scale_fill_manual(values=c("brown2", "lightcoral", "royalblue3", "deepskyblue", "limegreen")) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Group") +
  ylab("Chao Richness")
dev.off()

# Test normality
hist(adiv$chao, breaks=10)
qqnorm(adiv$chao)
qqline(adiv$chao)
shapiro.test(adiv$chao)
  # p-value = 1.736e-05
  # p-value = 3.96e-05
ks.test(adiv$chao, "pnorm", mean=mean(adiv$chao), sd=sd(adiv$chao))
  # p-value = 0.2134
  # p-value = 0.335

# Kruskal-Wallis
kruskal.test(formula = chao ~ Group, data = adiv)
  # p-value = 0.02779
  # p-value = 0.01146
kruskalmc(resp = chao ~ Group, data = adiv)
  # Significant:
    # Summer-Spring
kruskal.test(formula = chao ~ Group, data = adiv, subset=Diet=="Lab")
  # p-value = 0.119
  # p-value = 0.1177
kruskal.test(formula = chao ~ Sample_Type, data = adiv)
  # p-value = 0.1792
  # p-value = 0.2279
kruskal.test(formula = chao ~ Diet, data = adiv)
  # p-value = 0.004116
kruskal.test(formula = chao ~ Diet, data = adiv, subset=Season=="Summer")
  # p-value = 0.0208
wilcox.test(chao ~ Diet, data=adiv)
  # p-value = 0.002454


### Berger-Parker
# Color by group
ggplot(adiv, aes(x=Group, y=bergerparker, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  #facet_grid(.~Substrate) +
  #scale_fill_manual(values=c("gray95", "dimgray") )+
  xlab("Group") +
  ylab("Berger-Parker")
# Color by group, facet by sample type
ggplot(adiv, aes(x=Group, y=bergerparker, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  #scale_fill_manual(values=c("gray95", "dimgray") )+
  xlab("Group") +
  ylab("Berger-Parker")

# Test normality
hist(adiv$bergerparker, breaks=10)
qqnorm(adiv$bergerparker)
qqline(adiv$bergerparker)
shapiro.test(adiv$bergerparker)
  # p-value = 2.924e-05
ks.test(adiv$bergerparker, "pnorm", mean=mean(adiv$bergerparker), sd=sd(adiv$bergerparker))
  # p-value = 0.351

# Kruskal-Wallis
kruskal.test(formula = bergerparker ~ Group, data = adiv)
  # p-value = 0.4087
kruskal.test(formula = bergerparker ~ Group, data = adiv, subset=Diet=="Lab")
  # p-value = 0.7487
kruskal.test(formula = bergerparker ~ Sample_Type, data = adiv)
  # p-value = 0.594
kruskal.test(formula = bergerparker ~ Diet, data = adiv)
  # p-value = 0.03825
kruskal.test(formula = bergerparker ~ Diet, data = adiv, subset=Season=="Summer")
  # p-value = 0.1317
wilcox.test(bergerparker ~ Diet, data=adiv)
  # p-value = 0.03743


### Shannon
# Color by group
ggplot(adiv, aes(x=Group, y=shannon, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  #facet_grid(.~Substrate) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Group") +
  ylab("Shannon Diversity")
# Color by group, facet by sample type
ggplot(adiv, aes(x=Group, y=shannon, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Group") +
  ylab("Shannon Diversity")

# Test normality
hist(adiv$shannon, breaks=10)
qqnorm(adiv$shannon)
qqline(adiv$shannon)
shapiro.test(adiv$shannon)
  # p-value = 0.3431
ks.test(adiv$shannon, "pnorm", mean=mean(adiv$shannon), sd=sd(adiv$shannon))
  # p-value = 0.9152

# ANOVA
summary(aov(shannon ~ Group, data=adiv))
  # p-value = 0.0501
t.test(shannon ~ Sample_Type, data=adiv)
  # p-value = 0.8445
t.test(shannon ~ Diet, data=adiv)
  # p-value = 0.02371



### Inverse Simpson
# Color by group
tiff("InvSimp.tiff", width=6.5, height=3, units="in", res=600)
ggplot(adiv, aes(x=Group, y= invsimpson, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  #facet_grid(.~Substrate) +
  scale_fill_manual(values=c("brown2", "lightcoral", "royalblue3", "deepskyblue", "limegreen")) +
  xlab("Group") +
  ylab("Inverse Simpson Weighted Diversity")
dev.off()
# Color by group, facet by sample type
tiff("InvSimp.facet.tiff", width=11, height=3, units="in", res=600)
ggplot(adiv, aes(x=Group, y= invsimpson, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  scale_fill_manual(values=c("brown2", "lightcoral", "royalblue3", "deepskyblue", "limegreen")) +
  xlab("Group") +
  ylab("Inverse Simpson Weighted Diversity")
dev.off()


# Test normality
hist(adiv$invsimpson, breaks=10)
qqnorm(adiv$invsimpson)
qqline(adiv$invsimpson)
shapiro.test(adiv$invsimpson)
  # p-value = 6.667e-06
ks.test(adiv$invsimpson, "pnorm", mean=mean(adiv$invsimpson), sd=sd(adiv$invsimpson))
  # p-value = 0.02063

# Kruskal-Wallis
kruskal.test(formula = invsimpson ~ Group, data = adiv)
  # p-value = 0.3059
kruskal.test(formula = invsimpson ~ Group, data = adiv, subset=Diet=="Lab")
  # p-value = 0.6151
kruskal.test(formula = invsimpson ~ Sample_Type, data = adiv)
  # p-value = 0.7817
kruskal.test(formula = invsimpson ~ Diet, data = adiv)
  # p-value = 0.02565
kruskal.test(formula = invsimpson ~ Diet, data = adiv, subset=Season=="Summer")
  # p-value = 0.08753
wilcox.test(invsimpson ~ Diet, data=adiv)
  # p-value = 0.0239











adiv.rem.combos <- combn(x=levels(adiv$Group), m=2)
adiv.pvals <- data.frame(rep(999,10))
for(i in 1:ncol(adiv.rem.combos)){
  group1 <- which(adiv$Group == adiv.rem.combos[1,i])
  group2 <- which(adiv$Group == adiv.rem.combos[2,i])
  temp.df <- adiv[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv[group2,]
  test <- wilcox.test(Total_OTUs ~ Group, data=temp.df)
  adiv.pvals[i,1] <- test$p.value
  rownames(adiv.pvals)[i] <- paste(adiv.rem.combos[1,i], adiv.rem.combos[2,i])
}
colnames(adiv.pvals) <- "otusum.pval"
adiv.pvals$otusum.bonf <- p.adjust(adiv.pvals$otusum.pval, method="bonferroni")
adiv.pvals$otusum.BH <- p.adjust(adiv.pvals$otusum.pval, method="BH")

for(i in 1:ncol(adiv.rem.combos)){
  group1 <- which(adiv$Group == adiv.rem.combos[1,i])
  group2 <- which(adiv$Group == adiv.rem.combos[2,i])
  temp.df <- adiv[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv[group2,]
  test <- wilcox.test(chao ~ Group, data=temp.df)
  adiv.pvals[i,4] <- test$p.value
}
colnames(adiv.pvals)[4] <- "chao.pval"
adiv.pvals$chao.bonf <- p.adjust(adiv.pvals$chao.pval, method="bonferroni")
adiv.pvals$chao.BH <- p.adjust(adiv.pvals$chao.pval, method="BH")

for(i in 1:ncol(adiv.rem.combos)){
  group1 <- which(adiv$Group == adiv.rem.combos[1,i])
  group2 <- which(adiv$Group == adiv.rem.combos[2,i])
  temp.df <- adiv[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv[group2,]
  test <- wilcox.test(bergerparker ~ Group, data=temp.df)
  adiv.pvals[i,7] <- test$p.value
}
colnames(adiv.pvals)[7] <- "bp.pval"
adiv.pvals$bp.bonf <- p.adjust(adiv.pvals$bp.pval, method="bonferroni")
adiv.pvals$bp.BH <- p.adjust(adiv.pvals$bp.pval, method="BH")

aov.shannon.group <- aov(shannon ~ Group, data=adiv)
tukey.shannon <- TukeyHSD(aov.shannon.group)
adiv.pvals$shannon.tukey.pval<-tukey.shannon$Group[,4]

           
for(i in 1:ncol(adiv.rem.combos)){
  group1 <- which(adiv$Group == adiv.rem.combos[1,i])
  group2 <- which(adiv$Group == adiv.rem.combos[2,i])
  temp.df <- adiv[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv[group2,]
  test <- wilcox.test(invsimpson ~ Group, data=temp.df)
  adiv.pvals[i,11] <- test$p.value
}
colnames(adiv.pvals)[11] <- "invsimp.pval"
adiv.pvals$invsimp.bonf <- p.adjust(adiv.pvals$invsimp.pval, method="bonferroni")
adiv.pvals$invsimp.BH <- p.adjust(adiv.pvals$invsimp.pval, method="BH")


adiv.con <- adiv[which(adiv$Sample_Type=="Content"),]
adiv.con.pvals <- data.frame(rep(999,10))
for(i in 1:ncol(adiv.rem.combos)){
  group1 <- which(adiv.con$Group == adiv.rem.combos[1,i])
  group2 <- which(adiv.con$Group == adiv.rem.combos[2,i])
  temp.df <- adiv.con[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.con[group2,]
  test <- wilcox.test(Total_OTUs ~ Group, data=temp.df)
  adiv.con.pvals[i,1] <- test$p.value
  rownames(adiv.con.pvals)[i] <- paste(adiv.rem.combos[1,i], adiv.rem.combos[2,i])
}
colnames(adiv.con.pvals) <- "otusum.pval"
adiv.con.pvals$otusum.bonf <- p.adjust(adiv.con.pvals$otusum.pval, method="bonferroni")
adiv.con.pvals$otusum.BH <- p.adjust(adiv.con.pvals$otusum.pval, method="BH")

for(i in 1:ncol(adiv.rem.combos)){
  group1 <- which(adiv.con$Group == adiv.rem.combos[1,i])
  group2 <- which(adiv.con$Group == adiv.rem.combos[2,i])
  temp.df <- adiv.con[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.con[group2,]
  test <- wilcox.test(chao ~ Group, data=temp.df)
  adiv.con.pvals[i,4] <- test$p.value
}
colnames(adiv.con.pvals)[4] <- "chao.pval"
adiv.con.pvals$chao.bonf <- p.adjust(adiv.con.pvals$chao.pval, method="bonferroni")
adiv.con.pvals$chao.BH <- p.adjust(adiv.con.pvals$chao.pval, method="BH")

for(i in 1:ncol(adiv.rem.combos)){
  group1 <- which(adiv.con$Group == adiv.rem.combos[1,i])
  group2 <- which(adiv.con$Group == adiv.rem.combos[2,i])
  temp.df <- adiv.con[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.con[group2,]
  test <- wilcox.test(bergerparker ~ Group, data=temp.df)
  adiv.con.pvals[i,7] <- test$p.value
}
colnames(adiv.con.pvals)[7] <- "bp.pval"
adiv.con.pvals$bp.bonf <- p.adjust(adiv.con.pvals$bp.pval, method="bonferroni")
adiv.con.pvals$bp.BH <- p.adjust(adiv.con.pvals$bp.pval, method="BH")

aov.shannon.group <- aov(shannon ~ Group, data=adiv.con)
tukey.shannon <- TukeyHSD(aov.shannon.group)
adiv.con.pvals$shannon.tukey.pval<-tukey.shannon$Group[,4]

           
for(i in 1:ncol(adiv.rem.combos)){
  group1 <- which(adiv.con$Group == adiv.rem.combos[1,i])
  group2 <- which(adiv.con$Group == adiv.rem.combos[2,i])
  temp.df <- adiv.con[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.con[group2,]
  test <- wilcox.test(invsimpson ~ Group, data=temp.df)
  adiv.con.pvals[i,11] <- test$p.value
}
colnames(adiv.con.pvals)[11] <- "invsimp.pval"
adiv.con.pvals$invsimp.bonf <- p.adjust(adiv.con.pvals$invsimp.pval, method="bonferroni")
adiv.con.pvals$invsimp.BH <- p.adjust(adiv.con.pvals$invsimp.pval, method="BH")



adiv.muc <- adiv[which(adiv$Sample_Type=="Content"),]
adiv.muc.pvals <- data.frame(rep(999,10))
for(i in 1:ncol(adiv.rem.combos)){
  group1 <- which(adiv.muc$Group == adiv.rem.combos[1,i])
  group2 <- which(adiv.muc$Group == adiv.rem.combos[2,i])
  temp.df <- adiv.muc[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.muc[group2,]
  test <- wilcox.test(Total_OTUs ~ Group, data=temp.df)
  adiv.muc.pvals[i,1] <- test$p.value
  rownames(adiv.muc.pvals)[i] <- paste(adiv.rem.combos[1,i], adiv.rem.combos[2,i])
}
colnames(adiv.muc.pvals) <- "otusum.pval"
adiv.muc.pvals$otusum.bonf <- p.adjust(adiv.muc.pvals$otusum.pval, method="bonferroni")
adiv.muc.pvals$otusum.BH <- p.adjust(adiv.muc.pvals$otusum.pval, method="BH")

for(i in 1:ncol(adiv.rem.combos)){
  group1 <- which(adiv.muc$Group == adiv.rem.combos[1,i])
  group2 <- which(adiv.muc$Group == adiv.rem.combos[2,i])
  temp.df <- adiv.muc[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.muc[group2,]
  test <- wilcox.test(chao ~ Group, data=temp.df)
  adiv.muc.pvals[i,4] <- test$p.value
}
colnames(adiv.muc.pvals)[4] <- "chao.pval"
adiv.muc.pvals$chao.bonf <- p.adjust(adiv.muc.pvals$chao.pval, method="bonferroni")
adiv.muc.pvals$chao.BH <- p.adjust(adiv.muc.pvals$chao.pval, method="BH")

for(i in 1:ncol(adiv.rem.combos)){
  group1 <- which(adiv.muc$Group == adiv.rem.combos[1,i])
  group2 <- which(adiv.muc$Group == adiv.rem.combos[2,i])
  temp.df <- adiv.muc[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.muc[group2,]
  test <- wilcox.test(bergerparker ~ Group, data=temp.df)
  adiv.muc.pvals[i,7] <- test$p.value
}
colnames(adiv.muc.pvals)[7] <- "bp.pval"
adiv.muc.pvals$bp.bonf <- p.adjust(adiv.muc.pvals$bp.pval, method="bonferroni")
adiv.muc.pvals$bp.BH <- p.adjust(adiv.muc.pvals$bp.pval, method="BH")

aov.shannon.group <- aov(shannon ~ Group, data=adiv.muc)
tukey.shannon <- TukeyHSD(aov.shannon.group)
adiv.muc.pvals$shannon.tukey.pval<-tukey.shannon$Group[,4]

           
for(i in 1:ncol(adiv.rem.combos)){
  group1 <- which(adiv.muc$Group == adiv.rem.combos[1,i])
  group2 <- which(adiv.muc$Group == adiv.rem.combos[2,i])
  temp.df <- adiv.muc[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.muc[group2,]
  test <- wilcox.test(invsimpson ~ Group, data=temp.df)
  adiv.muc.pvals[i,11] <- test$p.value
}
colnames(adiv.muc.pvals)[11] <- "invsimp.pval"
adiv.muc.pvals$invsimp.bonf <- p.adjust(adiv.muc.pvals$invsimp.pval, method="bonferroni")
adiv.muc.pvals$invsimp.BH <- p.adjust(adiv.muc.pvals$invsimp.pval, method="BH")


adiv.pvals[11:20,] <- adiv.con.pvals
adiv.pvals[21:30,] <- adiv.muc.pvals
rows <- rownames(adiv.con.pvals)
for (i in 1:length(rows)){
  rows[i] <- paste(rows[i], "Content")
}
rownames(adiv.pvals)[11:20] <- rows
rows <- rownames(adiv.muc.pvals)
for (i in 1:length(rows)){
  rows[i] <- paste(rows[i], "Mucosa")
}
rownames(adiv.pvals)[21:30] <- rows

adiv.pvals <- adiv.pvals[,-7:-9]


adiv.group <- data.frame(rep(999,5))
for(i in 1:5){
  gro <- levels(adiv$Group)[i]
  adiv.temp <- adiv[which(adiv$Group==gro),]
  test <- wilcox.test(Total_OTUs ~ Sample_Type, data=adiv.temp)
  adiv.group[i,1] <- test$p.value
  test <- wilcox.test(chao ~ Sample_Type, data=adiv.temp)
  adiv.group[i,2] <- test$p.value
  test <- wilcox.test(bergerparker ~ Sample_Type, data=adiv.temp)
  adiv.group[i,3] <- test$p.value
  test <- t.test(shannon ~ Sample_Type, data=adiv.temp)
  adiv.group[i,4] <- test$p.value
  test <- wilcox.test(invsimpson ~ Sample_Type, data=adiv.temp)
  adiv.group[i,5] <- test$p.value
}
rownames(adiv.group) <- levels(adiv$Group)
colnames(adiv.group) <- c("otusum.pval", "chao.pval", "bp.pval", "shannon.pval", "invsimp.pval")
adiv.group$otusum.bonf <- p.adjust(adiv.group$otusum.pval, method="bonferroni")
adiv.group$otusum.BH <- p.adjust(adiv.group$otusum.pval, method="BH")
adiv.group$chao.bonf <- p.adjust(adiv.group$chao.pval, method="bonferroni")
adiv.group$chao.BH <- p.adjust(adiv.group$chao.pval, method="BH")
adiv.group$bp.bonf <- p.adjust(adiv.group$bp.pval, method="bonferroni")
adiv.group$bp.BH <- p.adjust(adiv.group$bp.pval, method="BH")
adiv.group$shannon.bonf <- p.adjust(adiv.group$shannon.pval, method="bonferroni")
adiv.group$shannon.BH <- p.adjust(adiv.group$shannon.pval, method="BH")
adiv.group$invsimp.bonf <- p.adjust(adiv.group$invsimp.pval, method="bonferroni")
adiv.group$invsimp.BH <- p.adjust(adiv.group$invsimp.pval, method="BH")


adiv.muc.pvals$invsimp.bonf <- p.adjust(adiv.muc.pvals$invsimp.pval, method="bonferroni")
adiv.muc.pvals$invsimp.BH <- p.adjust(adiv.muc.pvals$invsimp.pval, method="BH")




```


### Examine Phyla
```{r}
# Merge samples with the same taxonomic rank
goodphy <- tax_glom(physeq.rem, taxrank="Phylum")

# Transform each merged phylum count to rel abund
phy99 <- transform_sample_counts(goodphy, function(x){(x/sum(x))*100})

# Remove any phyla with <1% rel abund
phy99 <- prune_taxa(taxa_sums(phy99) > 1, phy99)

# Create rank abundance of phyla
barplot(sort(taxa_sums(phy99),TRUE)[1:20]/nsamples(phy99),las=2,cex.axis=.7)

# Summarize data
phy.df <- psmelt(phy99)
phy.df$Phylum <- ordered(phy.df$Phylum, levels=c("Firmicutes", "Bacteroidetes", "Verrucomicrobia", "Proteobacteria", "Unclassified", "Cyanobacteria", "Tenericutes", "Actinobacteria", "Elusimicrobia"))
phy.df$Phylum[which(is.na(phy.df$Phylum))] <- rep("Unclassified",18)
phy.sum <- phy.df %>%
  group_by(Diet, Sample_Type, Phylum) %>%
  summarize(Mean = mean(Abundance),
            Median = median(Abundance),
            SD = sd(Abundance),
            SE = (sd(Abundance)/(sqrt(length(Abundance)))),
            iqr = IQR(Abundance))

# Calculate IQR limits
phy.sum$iqr.min <- phy.sum$Median - 0.5*phy.sum$iqr
phy.sum[which(phy.sum$iqr.min < 0),10] <- 0
  # Any IQR min < 0, change to 0 (otherwise error bar won't plot)
phy.sum$iqr.max <- phy.sum$Median + 0.5*phy.sum$iqr


### Barplot ###
tiff("Phyla.prelim.tiff", width=12, height=3.5, units="in", res=600)
ggplot(phy.sum, aes(x=Phylum, y=Median, fill=Phylum)) +
  geom_bar(stat="identity", color="black") +
  geom_errorbar(aes(ymax=iqr.max, ymin=iqr.min), width=0.25) +
  facet_grid(Sample_Type ~ Group) +
  scale_fill_brewer(palette="Set1") +
  xlab("Phyla") +
  ylab("Median Relative Abundance for Phyla > 1%") +
  scale_y_continuous(limits=c(0,80),expand=c(0,0))+
  theme(axis.text.x = element_blank(),
        #axis.title.x = element_text(size=10),
        #axis.title.y = element_text(size=10),
        #strip.text.x = element_text(size=8),
        #strip.text.y = element_text(size=8),
        panel.spacing=unit(1, "lines")#,
        #legend.title = element_text(size = 8),
        #legend.text = element_text(size=8)
        )
dev.off()

#tiff("Phyla3.tiff", width=13, height=8, units="in", res=600)
ggplot(phy.sum, aes(x=Phylum, y=Median, fill=Phylum)) +
  geom_bar(stat="identity", color="black") +
  geom_errorbar(aes(ymax=iqr.max, ymin=iqr.min), width=0.25) +
  facet_grid(Sample_Type ~ Group) +
  scale_fill_brewer(palette="Set1") +
  xlab("Phyla") +
  ylab("Median Relative Abundance for Phyla > 1%") +
  scale_y_continuous(limits=c(0,80),expand=c(0,0))+
  theme(axis.text.x = element_blank(),
        axis.title.x = element_text(size=20),
        axis.title.y = element_text(size=20),
        strip.text.x = element_text(size=14),
        strip.text.y = element_text(size=14),
        panel.spacing=unit(1, "lines"),
        legend.title = element_text(size = 14),
        legend.text = element_text(size=12),
        axis.text.y = element_text(size=12))
#dev.off()

# Pull out otu table to test phyla
phy.num <- as.numeric(otu_table(phy99))

# Test normality
hist(phy.num, breaks=10)
qqnorm(phy.num)
qqline(phy.num)
shapiro.test(phy.num)
  # p-value < 2.2e-16
ks.test(phy.num, "pnorm", mean=mean(phy.num), sd=sd(phy.num))
  # p-value < 2.2e-16

# Get ready for stats
sampdf <- data.frame(sample_data(phy99))
sampdf$Relative_Abundance <- otu_table(phy99)
```




### Bray-Curtis NMDS Ordination
```{r}
### Bray NMDS
nmds <- ordinate(physeq=physeq.rem, method="NMDS", distance="bray")
  # Stress = 0.102554

plot_ordination(physeq=physeq.rem, ordination=nmds, color="Group", shape="Sample_Type")

sample_data(physeq.rem)$Elip <- paste(sample_data(physeq.rem)$Group)
elip.nmds <- data.frame(MDS1 = nmds$points[,1], MDS2 = nmds$points[,2],
                        Group = sample_data(physeq.rem)$Elip)
plot.new()
elip.ord <- ordiellipse(nmds, sample_data(physeq.rem)$Elip, display="sites", kind="se", conf=0.95, label=T)


elip.df <- data.frame()
for(i in levels(elip.nmds$Group)){
  elip.df <- rbind(elip.df, cbind(as.data.frame(with(elip.nmds[elip.nmds$Group==i,],
                                                     veganCovEllipse(elip.ord[[i]]$cov,
                                                                     elip.ord[[i]]$center,
                                                                     elip.ord[[i]]$scale))),
                                  group=i))
  
}


tiff("NMDS.tiff", width=6, height=5, units="in", res=600)
plot_ordination(physeq=physeq.rem, ordination=nmds, color="Group") +
  geom_path(data=elip.df, aes(x=NMDS1, y=NMDS2, colour=group), size=1, linetype=1) +
  guides(color=guide_legend(title="Group")) +
  scale_color_manual(values=c("brown2", "lightcoral", "royalblue3", "deepskyblue", "limegreen"))
dev.off()

tiff("NMDS.samptype.tiff", width=6, height=5, units="in", res=600)
plot_ordination(physeq=physeq.rem, ordination=nmds, color="Group", shape = "Sample_Type") +
  guides(color=guide_legend(title="Group")) +
  scale_color_manual(values=c("brown2", "lightcoral", "royalblue3", "deepskyblue", "limegreen")) +
  scale_shape_manual(values=c(19,2))
dev.off()

### PERMANOVA
sampdf <- data.frame(sample_data(physeq.rem))
bray<- phyloseq::distance(physeq=physeq.rem, method="bray")
adonis(bray~ Group, data=sampdf)
  # p-value = 0.001
beta.tax = betadisper(d=bray, group=sampdf$Group)
p <- permutest(beta.tax)
p$tab
  # p-value = 0.026
adonis(bray~ Sample_Type, data=sampdf)
  # p-value = 1
beta.tax = betadisper(d=bray, group=sampdf$Sample_Type)
p <- permutest(beta.tax)
p$tab
  # p-value = 0.192

combos <- combn(x=levels(sampdf$Group), m=2)
bray.pvals <- data.frame(rep(999,10))
for( i in 1:ncol(combos)){
  temp.physeq <- subset_samples(physeq.rem, Group%in% combos[,i])
  temp.sampdf <- data.frame(sample_data(temp.physeq))
  temp.bray <- phyloseq::distance(physeq=temp.physeq, method="bray")
  test <- adonis(temp.bray ~ Group, data=temp.sampdf)
  rownames(bray.pvals)[i] <- paste(combos[1,i], combos[2,i])
  bray.pvals[i,1]<- test[[1]]$`Pr(>F)`[1]
}
colnames(bray.pvals) <- "pval"
bray.pvals$Adj.bonf <- p.adjust(bray.pvals$pval, method="bonferroni")
bray.pvals$Adj.BH <- p.adjust(bray.pvals$pval, method="BH")

sampdf2 <- data.frame(sample_data(physeq.rem))
combos2 <- combn(x=levels(sampdf2$Group), m=2)
bray.pvals2 <- data.frame(rep(999,10))
for( i in 1:ncol(combos2)){
  temp.physeq2 <- subset_samples(physeq.rem, Group%in% combos2[,i])
  temp.sampdf2 <- data.frame(sample_data(temp.physeq2))
  temp.bray2 <- phyloseq::distance(physeq=temp.physeq2, method="bray")
  test2 <- adonis(temp.bray2 ~ Group, data=temp.sampdf2)
  rownames(bray.pvals2)[i] <- paste(combos2[1,i], combos2[2,i])
  bray.pvals2[i,1]<- test2[[1]]$`Pr(>F)`[1]
}
colnames(bray.pvals2) <- "pval"
bray.pvals2$Adj.bonf <- p.adjust(bray.pvals2$pval, method="bonferroni")
bray.pvals2$Adj.BH <- p.adjust(bray.pvals2$pval, method="BH")



sampdf <- data.frame(sample_data(physeq.rem))
bray<- phyloseq::distance(physeq=physeq.rem, method="bray")
adonis(bray~ Group, data=sampdf)

#pulls out p-value:
  test[[1]]$`Pr(>F)`[1]
  #https://stackoverflow.com/questions/3366506/extract-p-value-from-aov?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa
```


### Bray-Curtis PCoA Ordination
```{r}
### Bray NMDS
nmds <- ordinate(physeq=physeq.rem, method="NMDS", distance="bray")
  # Stress = 0.102554

plot_ordination(physeq=physeq.rem, ordination=nmds, color="Group", shape="Sample_Type")

bray.pcoa <- ordinate(physeq=physeq.rem, method="PCoA", distance="bray")
plot_ordination(physeq=physeq.rem, ordination=bray.pcoa, axes=c(1,2), color="Group", shape="Sample_Type")



plot_ordination(physeq=physeq.rem, ordination=nmds, color="Group") +
  geom_path(data=elip.df, aes(x=NMDS1, y=NMDS2, colour=group), size=1, linetype=1) +
  guides(color=guide_legend(title="Group")) +
  scale_color_manual(values=c("brown2", "lightcoral", "royalblue3", "deepskyblue", "limegreen"))






sample_data(physeq.rem)$ElipPCoA <- paste(sample_data(physeq.rem)$Group)
elip.pcoa <- data.frame(Axis1 = bray.pcoa$vectors[,1], Axis2 = bray.pcoa$vectors[,2],
                        Group = sample_data(physeq.rem)$ElipPCoA)
bray.pcoa.elip <- bray.pcoa
bray.pcoa.elip <- bray.pcoa.elip$vectors[,-3:-41]
  # ordiellipse can only work w/ 1 axes. If you have more than 2 (like in a PCoA), it won't work
plot.new()
elip.bray.pcoa.ord <- ordiellipse(bray.pcoa.elip, sample_data(physeq.rem)$ElipPCoA, display="sites", kind="se", conf=0.95, label=T)

veganCovEllipse <- function(cov, center = c(0, 0), scale = 1, npoints = 100) {
    theta <- (0:npoints) * 2 * pi/npoints
    Circle <- cbind(cos(theta), sin(theta))
    t(center + scale * t(Circle %*% chol(cov)))
}

elip.bray.pcoa.df <- data.frame()
for(i in levels(elip.bray.pcoa.ord$Group)){
  elip.bray.pcoa.df <- rbind(elip.bray.pcoa.df, cbind(as.data.frame(with(elip.pcoa[elip.pcoa$Group==i,],
                                                     veganCovEllipse(elip.bray.pcoa.ord[[i]]$cov,
                                                                     elip.bray.pcoa.ord[[i]]$center,
                                                                     elip.bray.pcoaord[[i]]$scale))),
                                  group=i))
  
}




plot_ordination(physeq=physeq.rem, ordination=bray.pcoa, color="Group") +
  geom_path(data=elip.bray.pcoa.df, aes(x=NMDS1, y=NMDS2, colour=group), size=1, linetype=1) +
  guides(color=guide_legend(title="Group")) +
  scale_color_manual(values=c("brown2", "lightcoral", "royalblue3", "deepskyblue", "limegreen"))


### PERMANOVA
sampdf <- data.frame(sample_data(physeq.rem))
bray<- phyloseq::distance(physeq=physeq.rem, method="bray")
adonis(bray~ Group, data=sampdf)
  # p-value = 0.001
beta.tax = betadisper(d=bray, group=sampdf$Group)
p <- permutest(beta.tax)
p$tab
  # p-value = 0.026
adonis(bray~ Sample_Type, data=sampdf)
  # p-value = 1
beta.tax = betadisper(d=bray, group=sampdf$Sample_Type)
p <- permutest(beta.tax)
p$tab
  # p-value = 0.192

combos <- combn(x=levels(sampdf$Group), m=2)
bray.pvals <- data.frame(rep(999,10))
for( i in 1:ncol(combos)){
  temp.physeq <- subset_samples(physeq.rem, Group%in% combos[,i])
  temp.sampdf <- data.frame(sample_data(temp.physeq))
  temp.bray <- phyloseq::distance(physeq=temp.physeq, method="bray")
  test <- adonis(temp.bray ~ Group, data=temp.sampdf)
  rownames(bray.pvals)[i] <- paste(combos[1,i], combos[2,i])
  bray.pvals[i,1]<- test[[1]]$`Pr(>F)`[1]
}
colnames(bray.pvals) <- "pval"
bray.pvals$Adj.bonf <- p.adjust(bray.pvals$pval, method="bonferroni")
bray.pvals$Adj.BH <- p.adjust(bray.pvals$pval, method="BH")

sampdf2 <- data.frame(sample_data(physeq.rem))
combos2 <- combn(x=levels(sampdf2$Group), m=2)
bray.pvals2 <- data.frame(rep(999,10))
for( i in 1:ncol(combos2)){
  temp.physeq2 <- subset_samples(physeq.rem, Group%in% combos2[,i])
  temp.sampdf2 <- data.frame(sample_data(temp.physeq2))
  temp.bray2 <- phyloseq::distance(physeq=temp.physeq2, method="bray")
  test2 <- adonis(temp.bray2 ~ Group, data=temp.sampdf2)
  rownames(bray.pvals2)[i] <- paste(combos2[1,i], combos2[2,i])
  bray.pvals2[i,1]<- test2[[1]]$`Pr(>F)`[1]
}
colnames(bray.pvals2) <- "pval"
bray.pvals2$Adj.bonf <- p.adjust(bray.pvals2$pval, method="bonferroni")
bray.pvals2$Adj.BH <- p.adjust(bray.pvals2$pval, method="BH")



sampdf <- data.frame(sample_data(physeq.rem))
bray<- phyloseq::distance(physeq=physeq.rem, method="bray")
adonis(bray~ Group, data=sampdf)

#pulls out p-value:
  test[[1]]$`Pr(>F)`[1]
  #https://stackoverflow.com/questions/3366506/extract-p-value-from-aov?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa
```




### Bray-Curtis Content
```{r}
### Bray NMDS

physeq.con <- subset_samples(physeq.rem, Sample_Type == "Content")
nmds.con <- ordinate(physeq=physeq.con, method="NMDS", distance="bray")
  # Stress = 0.1129313

plot_ordination(physeq=physeq.con, ordination=nmds.con, color="Group")


sample_data(physeq.con)$Elip <- paste(sample_data(physeq.con)$Group)
elip.nmds.con <- data.frame(MDS1 = nmds.con$points[,1], MDS2 = nmds.con$points[,2],
                        Group = sample_data(physeq.con)$Elip)
plot.new()
elip.ord.con <- ordiellipse(nmds.con, sample_data(physeq.con)$Elip, display="sites", kind="se", conf=0.95, label=T)

veganCovEllipse <- function(cov, center = c(0, 0), scale = 1, npoints = 100) {
    theta <- (0:npoints) * 2 * pi/npoints
    Circle <- cbind(cos(theta), sin(theta))
    t(center + scale * t(Circle %*% chol(cov)))
}

elip.con.df <- data.frame()
for(i in levels(elip.nmds.con$Group)){
  elip.con.df <- rbind(elip.con.df, cbind(as.data.frame(with(elip.nmds.con[elip.nmds.con$Group==i,],
                                                     veganCovEllipse(elip.ord.con[[i]]$cov,
                                                                     elip.ord.con[[i]]$center,
                                                                     elip.ord.con[[i]]$scale))),
                                  group=i))
  
}




plot_ordination(physeq=physeq.con, ordination=nmds.con, color="Group") +
  geom_path(data=elip.con.df, aes(x=NMDS1, y=NMDS2, colour=group), size=1, linetype=1) +
  guides(color=guide_legend(title="Group")) +
  scale_color_manual(values=c("brown2", "lightcoral", "royalblue3", "deepskyblue", "limegreen"))


### PERMANOVA
sampdf.con <- data.frame(sample_data(physeq.con))
bray<- phyloseq::distance(physeq=physeq.con, method="bray")
adonis(bray~ Group, data=sampdf.con)
  # p-value = 0.001
beta.tax = betadisper(d=bray, group=sampdf.con$Group)
p <- permutest(beta.tax)
p$tab
  # p-value = 0.54


combos <- combn(x=levels(sampdf.con$Group), m=2)
bray.pvals <- data.frame(rep(999,10))
for( i in 1:ncol(combos)){
  temp.physeq <- subset_samples(physeq.con, Group%in% combos[,i])
  temp.sampdf.con <- data.frame(sample_data(temp.physeq))
  temp.bray <- phyloseq::distance(physeq=temp.physeq, method="bray")
  test <- adonis(temp.bray ~ Group, data=temp.sampdf.con)
  rownames(bray.pvals)[i] <- paste(combos[1,i], combos[2,i])
  bray.pvals[i,1]<- test[[1]]$`Pr(>F)`[1]
}
colnames(bray.pvals) <- "pval"
bray.pvals$Adj.bonf <- p.adjust(bray.pvals$pval, method="bonferroni")
bray.pvals$Adj.BH <- p.adjust(bray.pvals$pval, method="BH")

sampdf.con2 <- data.frame(sample_data(physeq.rem))
combos2 <- combn(x=levels(sampdf.con2$Group), m=2)
bray.pvals2 <- data.frame(rep(999,10))
for( i in 1:ncol(combos2)){
  temp.physeq2 <- subset_samples(physeq.rem, Group%in% combos2[,i])
  temp.sampdf.con2 <- data.frame(sample_data(temp.physeq2))
  temp.bray2 <- phyloseq::distance(physeq=temp.physeq2, method="bray")
  test2 <- adonis(temp.bray2 ~ Group, data=temp.sampdf.con2)
  rownames(bray.pvals2)[i] <- paste(combos2[1,i], combos2[2,i])
  bray.pvals2[i,1]<- test2[[1]]$`Pr(>F)`[1]
}
colnames(bray.pvals2) <- "pval"
bray.pvals2$Adj.bonf <- p.adjust(bray.pvals2$pval, method="bonferroni")
bray.pvals2$Adj.BH <- p.adjust(bray.pvals2$pval, method="BH")
```



### Bray-Curtis Mucosa
```{r}
### Bray NMDS

physeq.muc <- subset_samples(physeq.rem, Sample_Type == "Mucosa")
nmds.muc <- ordinate(physeq=physeq.muc, method="NMDS", distance="bray")
  # Stress = 0.08935057

plot_ordination(physeq=physeq.muc, ordination=nmds.muc, color="Group")


sample_data(physeq.muc)$Elip <- paste(sample_data(physeq.muc)$Group)
elip.nmds.muc <- data.frame(MDS1 = nmds.muc$points[,1], MDS2 = nmds.muc$points[,2],
                        Group = sample_data(physeq.muc)$Elip)
plot.new()
elip.ord.muc <- ordiellipse(nmds.muc, sample_data(physeq.muc)$Elip, display="sites", kind="se", conf=0.95, label=T)

veganCovEllipse <- function(cov, center = c(0, 0), scale = 1, npoints = 100) {
    theta <- (0:npoints) * 2 * pi/npoints
    Circle <- cbind(cos(theta), sin(theta))
    t(center + scale * t(Circle %*% chol(cov)))
}

elip.muc.df <- data.frame()
for(i in levels(elip.nmds.muc$Group)){
  elip.muc.df <- rbind(elip.muc.df, cbind(as.data.frame(with(elip.nmds.muc[elip.nmds.muc$Group==i,],
                                                     veganCovEllipse(elip.ord.muc[[i]]$cov,
                                                                     elip.ord.muc[[i]]$center,
                                                                     elip.ord.muc[[i]]$scale))),
                                  group=i))
  
}




plot_ordination(physeq=physeq.muc, ordination=nmds.muc, color="Group") +
  geom_path(data=elip.muc.df, aes(x=NMDS1, y=NMDS2, colour=group), size=1, linetype=1) +
  guides(color=guide_legend(title="Group")) +
  scale_color_manual(values=c("brown2", "lightcoral", "royalblue3", "deepskyblue", "limegreen"))


### PERMANOVA
sampdf.con <- data.frame(sample_data(physeq.muc))
bray<- phyloseq::distance(physeq=physeq.muc, method="bray")
adonis(bray~ Group, data=sampdf.con)
  # p-value = 0.001
beta.tax = betadisper(d=bray, group=sampdf.con$Group)
p <- permutest(beta.tax)
p$tab
  # p-value = 0.54


combos <- combn(x=levels(sampdf.con$Group), m=2)
bray.pvals <- data.frame(rep(999,10))
for( i in 1:ncol(combos)){
  temp.physeq <- subset_samples(physeq.muc, Group%in% combos[,i])
  temp.sampdf.con <- data.frame(sample_data(temp.physeq))
  temp.bray <- phyloseq::distance(physeq=temp.physeq, method="bray")
  test <- adonis(temp.bray ~ Group, data=temp.sampdf.con)
  rownames(bray.pvals)[i] <- paste(combos[1,i], combos[2,i])
  bray.pvals[i,1]<- test[[1]]$`Pr(>F)`[1]
}
colnames(bray.pvals) <- "pval"
bray.pvals$Adj.bonf <- p.adjust(bray.pvals$pval, method="bonferroni")
bray.pvals$Adj.BH <- p.adjust(bray.pvals$pval, method="BH")

sampdf.con2 <- data.frame(sample_data(physeq.rem))
combos2 <- combn(x=levels(sampdf.con2$Group), m=2)
bray.pvals2 <- data.frame(rep(999,10))
for( i in 1:ncol(combos2)){
  temp.physeq2 <- subset_samples(physeq.rem, Group%in% combos2[,i])
  temp.sampdf.con2 <- data.frame(sample_data(temp.physeq2))
  temp.bray2 <- phyloseq::distance(physeq=temp.physeq2, method="bray")
  test2 <- adonis(temp.bray2 ~ Group, data=temp.sampdf.con2)
  rownames(bray.pvals2)[i] <- paste(combos2[1,i], combos2[2,i])
  bray.pvals2[i,1]<- test2[[1]]$`Pr(>F)`[1]
}
colnames(bray.pvals2) <- "pval"
bray.pvals2$Adj.bonf <- p.adjust(bray.pvals2$pval, method="bonferroni")
bray.pvals2$Adj.BH <- p.adjust(bray.pvals2$pval, method="BH")
```





### Simper
```{r}
# Change Group names to be compatible (no "_")
physeq.simp <- physeq.rem
rename.samp <- data.frame(sample_data(physeq.simp))
rename.wild <- which(data.frame(sample_data(physeq.simp))$Group == "Summer_Wild")
rename.lab <- which(data.frame(sample_data(physeq.simp))$Group == "Summer_Lab")
levels(rename.samp$Group) <- c("SummerWild", "SummerLab", "Torpor", "IBA", "Spring")
physeq.simp <- merge_phyloseq(otu_table(physeq.rem), sample_data(rename.samp), tax_table(physeq.rem))


# All
simper.pretty(data.frame(otu_table(physeq.simp)),
              data.frame(sample_data(physeq.simp)),
              c("Group", "Sample_Type"),
              perc_cutoff=0.5, low_cutoff='y', low_val=0.01,
              output_name='all')
all.simper <- read.csv("all_clean_simper.csv")
kruskal.pretty(data.frame(otu_table(physeq.simp)),
               data.frame(sample_data(physeq.simp)),
               csv = all.simper,
               c("Group", "Sample_Type"),
               output_name = 'all',
               taxonomy = data.frame(tax_table(physeq.simp)))
all.simper.kw <- read.csv("all_krusk_simper.csv")
for(i in 1:nrow(all.simper.kw)){
  save <- which(rownames(data.frame(tax_table(physeq.simp))) == all.simper.kw$OTU[i])
  all.simper.kw$Taxonomy[i] <-
    paste(data.frame(tax_table(physeq.simp))[i,2], "-",
          data.frame(tax_table(physeq.simp))[i,3], "-",
          data.frame(tax_table(physeq.simp))[i,4], "-",
          data.frame(tax_table(physeq.simp))[i,5], "-",
          data.frame(tax_table(physeq.simp))[i,6])
}
write.table(all.simper.kw, "all_krusk_simper.csv", sep=",")

# Group
simper.pretty(data.frame(otu_table(physeq.simp)),
              data.frame(sample_data(physeq.simp)),
              c("Group"),
              perc_cutoff=0.5, low_cutoff='y', low_val=0.01,
              output_name='group')
group.simper <- read.csv("group_clean_simper.csv")
kruskal.pretty(data.frame(otu_table(physeq.simp)),
               data.frame(sample_data(physeq.simp)),
               csv = group.simper,
               c("Group"),
               output_name = 'group',
               taxonomy = data.frame(tax_table(physeq.simp)))
group.simper.kw <- read.csv("group_krusk_simper.csv")
for(i in 1:nrow(group.simper.kw)){
  save <- which(rownames(data.frame(tax_table(physeq.simp))) == group.simper.kw$OTU[i])
  group.simper.kw$Taxonomy[i] <-
    paste(data.frame(tax_table(physeq.simp))[i,2], "-",
          data.frame(tax_table(physeq.simp))[i,3], "-",
          data.frame(tax_table(physeq.simp))[i,4], "-",
          data.frame(tax_table(physeq.simp))[i,5], "-",
          data.frame(tax_table(physeq.simp))[i,6])
}
write.table(group.simper.kw, "group_krusk_simper.csv", sep=",")

# Content
physeq.con <- subset_samples(physeq.simp, Sample_Type == "Content")
simper.pretty(data.frame(otu_table(physeq.con)),
              data.frame(sample_data(physeq.con)),
              c("Group"),
              perc_cutoff=0.5, low_cutoff='y', low_val=0.01,
              output_name='con')
con.simper <- read.csv("con_clean_simper.csv")
kruskal.pretty(data.frame(otu_table(physeq.con)),
               data.frame(sample_data(physeq.con)),
               csv = con.simper,
               c("Group"),
               output_name = 'con',
               taxonomy = data.frame(tax_table(physeq.con)))
con.simper.kw <- read.csv("con_krusk_simper.csv")
for(i in 1:nrow(con.simper.kw)){
  save <- which(rownames(data.frame(tax_table(physeq.con))) == con.simper.kw$OTU[i])
  con.simper.kw$Taxonomy[i] <-
    paste(data.frame(tax_table(physeq.con))[i,2], "-",
          data.frame(tax_table(physeq.con))[i,3], "-",
          data.frame(tax_table(physeq.con))[i,4], "-",
          data.frame(tax_table(physeq.con))[i,5], "-",
          data.frame(tax_table(physeq.con))[i,6])
}
write.table(con.simper.kw, "con_krusk_simper.csv", sep=",")

# Mucosa
physeq.muc <- subset_samples(physeq.simp, Sample_Type == "Mucosa")
simper.pretty(data.frame(otu_table(physeq.muc)),
              data.frame(sample_data(physeq.muc)),
              c("Group"),
              perc_cutoff=0.5, low_cutoff='y', low_val=0.01,
              output_name='muc')
muc.simper <- read.csv("muc_clean_simper.csv")
kruskal.pretty(data.frame(otu_table(physeq.muc)),
               data.frame(sample_data(physeq.muc)),
               csv = muc.simper,
               c("Group"),
               output_name = 'muc',
               taxonomy = data.frame(tax_table(physeq.muc)))
muc.simper.kw <- read.csv("muc_krusk_simper.csv")
for(i in 1:nrow(muc.simper.kw)){
  save <- which(rownames(data.frame(tax_table(physeq.muc))) == muc.simper.kw$OTU[i])
  muc.simper.kw$Taxonomy[i] <-
    paste(data.frame(tax_table(physeq.muc))[i,2], "-",
          data.frame(tax_table(physeq.muc))[i,3], "-",
          data.frame(tax_table(physeq.muc))[i,4], "-",
          data.frame(tax_table(physeq.muc))[i,5], "-",
          data.frame(tax_table(physeq.muc))[i,6])
}
write.table(muc.simper.kw, "muc_krusk_simper.csv", sep=",")

# Summer Wild
physeq.wil <- subset_samples(physeq.simp, Group == "SummerWild")
simper.pretty(data.frame(otu_table(physeq.wil)),
              data.frame(sample_data(physeq.wil)),
              c("Sample_Type"),
              perc_cutoff=0.5, low_cutoff='y', low_val=0.01,
              output_name='wil')
wil.simper <- read.csv("wil_clean_simper.csv")
kruskal.pretty(data.frame(otu_table(physeq.wil)),
               data.frame(sample_data(physeq.wil)),
               csv = wil.simper,
               c("Sample_Type"),
               output_name = 'wil',
               taxonomy = data.frame(tax_table(physeq.wil)))
wil.simper.kw <- read.csv("wil_krusk_simper.csv")
for(i in 1:nrow(wil.simper.kw)){
  save <- which(rownames(data.frame(tax_table(physeq.wil))) == wil.simper.kw$OTU[i])
  wil.simper.kw$Taxonomy[i] <-
    paste(data.frame(tax_table(physeq.wil))[i,2], "-",
          data.frame(tax_table(physeq.wil))[i,3], "-",
          data.frame(tax_table(physeq.wil))[i,4], "-",
          data.frame(tax_table(physeq.wil))[i,5], "-",
          data.frame(tax_table(physeq.wil))[i,6])
}
write.table(wil.simper.kw, "wil_krusk_simper.csv", sep=",")

# Summer Lab
physeq.lab <- subset_samples(physeq.simp, Group == "SummerLab")
simper.pretty(data.frame(otu_table(physeq.lab)),
              data.frame(sample_data(physeq.lab)),
              c("Sample_Type"),
              perc_cutoff=0.5, low_cutoff='y', low_val=0.01,
              output_name='lab')
lab.simper <- read.csv("lab_clean_simper.csv")
kruskal.pretty(data.frame(otu_table(physeq.lab)),
               data.frame(sample_data(physeq.lab)),
               csv = lab.simper,
               c("Sample_Type"),
               output_name = 'lab',
               taxonomy = data.frame(tax_table(physeq.lab)))
lab.simper.kw <- read.csv("lab_krusk_simper.csv")
for(i in 1:nrow(lab.simper.kw)){
  save <- which(rownames(data.frame(tax_table(physeq.lab))) == lab.simper.kw$OTU[i])
  lab.simper.kw$Taxonomy[i] <-
    paste(data.frame(tax_table(physeq.lab))[i,2], "-",
          data.frame(tax_table(physeq.lab))[i,3], "-",
          data.frame(tax_table(physeq.lab))[i,4], "-",
          data.frame(tax_table(physeq.lab))[i,5], "-",
          data.frame(tax_table(physeq.lab))[i,6])
}
write.table(lab.simper.kw, "lab_krusk_simper.csv", sep=",")

# Torpor
physeq.tor <- subset_samples(physeq.simp, Group == "Torpor")
simper.pretty(data.frame(otu_table(physeq.tor)),
              data.frame(sample_data(physeq.tor)),
              c("Sample_Type"),
              perc_cutoff=0.5, low_cutoff='y', low_val=0.01,
              output_name='tor')
tor.simper <- read.csv("tor_clean_simper.csv")
kruskal.pretty(data.frame(otu_table(physeq.tor)),
               data.frame(sample_data(physeq.tor)),
               csv = tor.simper,
               c("Sample_Type"),
               output_name = 'tor',
               taxonomy = data.frame(tax_table(physeq.tor)))
tor.simper.kw <- read.csv("tor_krusk_simper.csv")
for(i in 1:nrow(tor.simper.kw)){
  save <- which(rownames(data.frame(tax_table(physeq.tor))) == tor.simper.kw$OTU[i])
  tor.simper.kw$Taxonomy[i] <-
    paste(data.frame(tax_table(physeq.tor))[i,2], "-",
          data.frame(tax_table(physeq.tor))[i,3], "-",
          data.frame(tax_table(physeq.tor))[i,4], "-",
          data.frame(tax_table(physeq.tor))[i,5], "-",
          data.frame(tax_table(physeq.tor))[i,6])
}
write.table(tor.simper.kw, "tor_krusk_simper.csv", sep=",")

# IBA
physeq.iba <- subset_samples(physeq.simp, Group == "IBA")
simper.pretty(data.frame(otu_table(physeq.iba)),
              data.frame(sample_data(physeq.iba)),
              c("Sample_Type"),
              perc_cutoff=0.5, low_cutoff='y', low_val=0.01,
              output_name='iba')
iba.simper <- read.csv("iba_clean_simper.csv")
kruskal.pretty(data.frame(otu_table(physeq.iba)),
               data.frame(sample_data(physeq.iba)),
               csv = iba.simper,
               c("Sample_Type"),
               output_name = 'iba',
               taxonomy = data.frame(tax_table(physeq.iba)))
iba.simper.kw <- read.csv("iba_krusk_simper.csv")
for(i in 1:nrow(iba.simper.kw)){
  save <- which(rownames(data.frame(tax_table(physeq.iba))) == iba.simper.kw$OTU[i])
  iba.simper.kw$Taxonomy[i] <-
    paste(data.frame(tax_table(physeq.iba))[i,2], "-",
          data.frame(tax_table(physeq.iba))[i,3], "-",
          data.frame(tax_table(physeq.iba))[i,4], "-",
          data.frame(tax_table(physeq.iba))[i,5], "-",
          data.frame(tax_table(physeq.iba))[i,6])
}
write.table(iba.simper.kw, "iba_krusk_simper.csv", sep=",")

# Spring
physeq.spr <- subset_samples(physeq.simp, Group == "Spring")
simper.pretty(data.frame(otu_table(physeq.spr)),
              data.frame(sample_data(physeq.spr)),
              c("Sample_Type"),
              perc_cutoff=0.5, low_cutoff='y', low_val=0.01,
              output_name='spr')
spr.simper <- read.csv("spr_clean_simper.csv")
kruskal.pretty(data.frame(otu_table(physeq.spr)),
               data.frame(sample_data(physeq.spr)),
               csv = spr.simper,
               c("Sample_Type"),
               output_name = 'spr',
               taxonomy = data.frame(tax_table(physeq.spr)))
spr.simper.kw <- read.csv("spr_krusk_simper.csv")
for(i in 1:nrow(spr.simper.kw)){
  save <- which(rownames(data.frame(tax_table(physeq.spr))) == spr.simper.kw$OTU[i])
  spr.simper.kw$Taxonomy[i] <-
    paste(data.frame(tax_table(physeq.spr))[i,2], "-",
          data.frame(tax_table(physeq.spr))[i,3], "-",
          data.frame(tax_table(physeq.spr))[i,4], "-",
          data.frame(tax_table(physeq.spr))[i,5], "-",
          data.frame(tax_table(physeq.spr))[i,6])
}
write.table(spr.simper.kw, "spr_krusk_simper.csv", sep=",")




### BH CORRECTION FOR ALL SIMPER COMPARISONS
all.simper.kw$Group <- rep("All", nrow(all.simper.kw))
all.simper.kw$OTU <- as.character(all.simper.kw$OTU)
all.simper.kw$Comparison <- as.character(all.simper.kw$Comparison)
all.simper.kw$Taxonomy <- as.character(all.simper.kw$Taxonomy)

con.simper.kw$Group <- rep("Content", nrow(con.simper.kw))
con.simper.kw$OTU <- as.character(con.simper.kw$OTU)
con.simper.kw$Comparison <- as.character(con.simper.kw$Comparison)
con.simper.kw$Taxonomy <- as.character(con.simper.kw$Taxonomy)

muc.simper.kw$Group <- rep("Mucosa", nrow(muc.simper.kw))
muc.simper.kw$OTU <- as.character(muc.simper.kw$OTU)
muc.simper.kw$Comparison <- as.character(muc.simper.kw$Comparison)
muc.simper.kw$Taxonomy <- as.character(muc.simper.kw$Taxonomy)

wil.simper.kw$Group <- rep("Summer_Wild", nrow(wil.simper.kw))
wil.simper.kw$OTU <- as.character(wil.simper.kw$OTU)
wil.simper.kw$Comparison <- as.character(wil.simper.kw$Comparison)
wil.simper.kw$Taxonomy <- as.character(wil.simper.kw$Taxonomy)

lab.simper.kw$Group <- rep("Summer_Lab", nrow(lab.simper.kw))
lab.simper.kw$OTU <- as.character(lab.simper.kw$OTU)
lab.simper.kw$Comparison <- as.character(lab.simper.kw$Comparison)
lab.simper.kw$Taxonomy <- as.character(lab.simper.kw$Taxonomy)

tor.simper.kw$Group <- rep("Torpor", nrow(tor.simper.kw))
tor.simper.kw$OTU <- as.character(tor.simper.kw$OTU)
tor.simper.kw$Comparison <- as.character(tor.simper.kw$Comparison)
tor.simper.kw$Taxonomy <- as.character(tor.simper.kw$Taxonomy)

iba.simper.kw$Group <- rep("IBA", nrow(iba.simper.kw))
iba.simper.kw$OTU <- as.character(iba.simper.kw$OTU)
iba.simper.kw$Comparison <- as.character(iba.simper.kw$Comparison)
iba.simper.kw$Taxonomy <- as.character(iba.simper.kw$Taxonomy)

spr.simper.kw$Group <- rep("Spring", nrow(spr.simper.kw))
spr.simper.kw$OTU <- as.character(spr.simper.kw$OTU)
spr.simper.kw$Comparison <- as.character(spr.simper.kw$Comparison)
spr.simper.kw$Taxonomy <- as.character(spr.simper.kw$Taxonomy)

simper.all <- all.simper.kw
simper.all[(nrow(simper.all)+1):(nrow(simper.all)+nrow(con.simper.kw)),] <- con.simper.kw
simper.all[(nrow(simper.all)+1):(nrow(simper.all)+nrow(muc.simper.kw)),] <- muc.simper.kw
simper.all[(nrow(simper.all)+1):(nrow(simper.all)+nrow(wil.simper.kw)),] <- wil.simper.kw
simper.all[(nrow(simper.all)+1):(nrow(simper.all)+nrow(lab.simper.kw)),] <- lab.simper.kw
simper.all[(nrow(simper.all)+1):(nrow(simper.all)+nrow(tor.simper.kw)),] <- tor.simper.kw
simper.all[(nrow(simper.all)+1):(nrow(simper.all)+nrow(iba.simper.kw)),] <- iba.simper.kw
simper.all[(nrow(simper.all)+1):(nrow(simper.all)+nrow(spr.simper.kw)),] <- spr.simper.kw
simper.all$fdr_krusk_p.val <- p.adjust(simper.all$krusk_p.val, "BH")
write.table(simper.all, "simper.csv", sep=",")



stevia.simper.all$fdr_krusk_p.val <- p.adjust(stevia.simper.all$krusk_p.val, "BH")
write.table(stevia.simper.all, "stevia.simper.nosex.csv", sep=",")


stevia.pre.simper.kw$Group <- rep("Pre", nrow(stevia.pre.simper.kw))
stevia.pre.simper.kw$OTU <- as.character(stevia.pre.simper.kw$OTU)
stevia.pre.simper.kw$Comparison <- as.character(stevia.pre.simper.kw$Comparison)
stevia.pre.simper.kw$Taxonomy <- as.character(stevia.pre.simper.kw$Taxonomy)
stevia.post.simper.kw$Group <- rep("Post", nrow(stevia.post.simper.kw))
stevia.post.simper.kw$OTU <- as.character(stevia.post.simper.kw$OTU)
stevia.post.simper.kw$Comparison <- as.character(stevia.post.simper.kw$Comparison)
stevia.post.simper.kw$Taxonomy <- as.character(stevia.post.simper.kw$Taxonomy)
stevia.hf.simper.kw$Group <- rep("High Fat", nrow(stevia.hf.simper.kw))
stevia.hf.simper.kw$OTU <- as.character(stevia.hf.simper.kw$OTU)
stevia.hf.simper.kw$Comparison <- as.character(stevia.hf.simper.kw$Comparison)
stevia.hf.simper.kw$Taxonomy <- as.character(stevia.hf.simper.kw$Taxonomy)
stevia.lf.simper.kw$Group <- rep("Low Fat", nrow(stevia.lf.simper.kw))
stevia.lf.simper.kw$OTU <- as.character(stevia.lf.simper.kw$OTU)
stevia.lf.simper.kw$Comparison <- as.character(stevia.lf.simper.kw$Comparison)
stevia.lf.simper.kw$Taxonomy <- as.character(stevia.lf.simper.kw$Taxonomy)
stevia.sc.simper.kw$Group <- rep("Saccharin", nrow(stevia.sc.simper.kw))
stevia.sc.simper.kw$OTU <- as.character(stevia.sc.simper.kw$OTU)
stevia.sc.simper.kw$Comparison <- as.character(stevia.sc.simper.kw$Comparison)
stevia.sc.simper.kw$Taxonomy <- as.character(stevia.sc.simper.kw$Taxonomy)
stevia.sc.simper.kw$Group <- as.character(stevia.sc.simper.kw$Group)
stevia.tv.simper.kw$Group <- rep("Stevia", nrow(stevia.tv.simper.kw))
stevia.tv.simper.kw$OTU <- as.character(stevia.tv.simper.kw$OTU)
stevia.tv.simper.kw$Comparison <- as.character(stevia.tv.simper.kw$Comparison)
stevia.tv.simper.kw$Taxonomy <- as.character(stevia.tv.simper.kw$Taxonomy)
stevia.tv.simper.kw$Group <- as.character(stevia.tv.simper.kw$Group)
stevia.simper.all <- stevia.pre.simper.kw
stevia.simper.all[(nrow(stevia.simper.all)+1):(nrow(stevia.simper.all)+nrow(stevia.post.simper.kw)),] <- stevia.post.simper.kw
stevia.simper.all[(nrow(stevia.simper.all)+1):(nrow(stevia.simper.all)+nrow(stevia.hf.simper.kw)),] <- stevia.hf.simper.kw
stevia.simper.all[(nrow(stevia.simper.all)+1):(nrow(stevia.simper.all)+nrow(stevia.lf.simper.kw)),] <- stevia.lf.simper.kw
stevia.simper.all[(nrow(stevia.simper.all)+1):(nrow(stevia.simper.all)+nrow(stevia.sc.simper.kw)),] <- stevia.sc.simper.kw
stevia.simper.all[(nrow(stevia.simper.all)+1):(nrow(stevia.simper.all)+nrow(stevia.tv.simper.kw)),] <- stevia.tv.simper.kw
stevia.simper.all$fdr_krusk_p.val <- p.adjust(stevia.simper.all$krusk_p.val, "BH")
write.table(stevia.simper.all, "stevia.simper.nosex.csv", sep=",")
```



### Cyanobacteria???
```{r}
cya <- subset_taxa(physeq.rem, Phylum == "Cyanobacteria")
cya.tax <- data.frame(tax_table(cya))
cya.rel <- transform_sample_counts(cya, function(x){(x/sum(x))*100})
cya.rel <- subset_samples(cya.rel, sample_names(cya.rel)!= "CC1_923_S")
cya.rel <- subset_samples(cya.rel, sample_names(cya.rel)!= "CC1_925_I")
cya.rel <- subset_samples(cya.rel, sample_names(cya.rel)!= "CM1_916_P")
cya.rel <- prune_taxa(taxa_sums(cya.rel)>0, cya.rel)
View(data.frame(otu_table(cya.rel)))
View(data.frame(tax_table(cya.rel)))
```




### Jaccard Ordination
```{r}
jac <- ordinate(physeq=physeq.use, method="NMDS", distance="jaccard")
  # stress =  0.1026393

plot_ordination(physeq=physeq.use, ordination=jac, color="Group", shape="Sample_Type")

# Try removing that insanely crazy Cellobiose ABX sample with all Proteos
physeq.use.rem <- subset_samples(physeq.use=physeq.use, sample_names(physeq.use) != "CC1_S25")
jac.rem <- ordinate(physeq.use=physeq.use.rem, method="NMDS", distance="jaccard")
  # Stress = 0.1032307 

plot_ordination(physeq.use=physeq.use.rem, ordination=jac.rem, color="ABX", shape="Substrate")
```








### Play with ellipses
```{r}
### Bray NMDS
# Try removing that insanely crazy Cellobiose ABX sample with all Proteos
physeq.use.rem <- subset_samples(physeq.use=physeq.use, sample_names(physeq.use) != "CC1_S25")
nmds.rem <- ordinate(physeq.use=physeq.use.rem, method="NMDS", distance="bray")
  # Stress = 0.1233697 

plot_ordination(physeq.use=physeq.use.rem, ordination=nmds.rem, color="ABX", shape="Substrate") +
  stat_ellipse(type = "norm", linetype = 2) + stat_ellipse(type = "t")


# https://stackoverflow.com/questions/13794419/plotting-ordiellipse-function-from-vegan-package-onto-nmds-plot-created-in-ggplo

elip.nmds <- data.frame(MDS1 = nmds.rem$points[,1], MDS2 = nmds.rem$points[,2],
                        ABX = sample_data(physeq.use.rem)$ABX)
plot.new()
elip.ord <- ordiellipse(nmds.rem, sample_data(physeq.use.rem)$ABX, display="sites", kind="se", conf=0.95, label=T)


veganCovEllipse <- function(cov, center = c(0, 0), scale = 1, npoints = 100) {
    theta <- (0:npoints) * 2 * pi/npoints
    Circle <- cbind(cos(theta), sin(theta))
    t(center + scale * t(Circle %*% chol(cov)))
}


elip.df <- data.frame()
for(i in levels(elip.nmds$ABX)){
  elip.df <- rbind(elip.df, cbind(as.data.frame(with(elip.nmds[elip.nmds$ABX==i,],
                                                     veganCovEllipse(elip.ord[[i]]$cov,
                                                                     elip.ord[[i]]$center,
                                                                     elip.ord[[i]]$scale))),
                                  group=i))
  
}


plot_ordination(physeq=physeq.use, ordination=nmds.rem, color="Group") +
  geom_path(data=elip.df, aes(x=NMDS1, y=NMDS2, colour=group), size=1, linetype=1) +
  scale_color_manual(values=c("brown2", "lightcoral", "royalblue3", "deepskyblue", "limegreen"))

```



### Remove 3916 outlier
```{r}
### TLDR: Removing it doesn't make a very large difference-- certainly not the diff btwn sig vs. not sig
# Squirrel 916 (Spring) is an outlier
  # Both content & mucosa is WAY LESS DIVERSE tan everything else
# 3916 metadata:
  # Weight to warm = 97
    # Normal = >110
  # Weight at sacrifice = 122
    # Normal = >145
  # Sacrifice body temp = 34
    # Normal = ~37

### New phyloseq object
physeq.use <- subset_samples(physeq=physeq.rem, sample_data(physeq.rem)$ID != 3916)

######### Alpha Diversity #########

adiv <- data.frame(sample_data(physeq.use))

### Total OTUs ###
shared = "mothur_output/final.shared"
taxonomy = "mothur_output/final.taxonomy"
mothurdata = import_mothur(
  mothur_shared_file = shared,
  mothur_constaxonomy_file = taxonomy)
tax_table(mothurdata) <- cbind(tax_table(mothurdata), 
                               row.names(tax_table(mothurdata)))
colnames(tax_table(mothurdata)) <- 
  c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus", "Species")
# Read in metadata
meta <- read.csv("metadata.csv")
colnames(meta)[1] <- "Sample"
otu.tot <- data.frame(sample_names(mothurdata))
# Pull out # of OTUs from all samples
otu.tot$Total_OTUs <- rep("NA", 77)
for(i in 1:77){
  otu.tot[i,2] <- length(which(otu_table(mothurdata)[,i] != 0))
}
# Pull out the data from just the samples we kept
keep <- data.frame(rep("NA",45))
keep[,2] <- rep("NA", 45)
for(i in 1:45){
  x <- which(otu.tot$sample_names.mothurdata. == sample_names(physeq.use)[i])
  keep[i,2] <- otu.tot[x,2]
}
keep[,1] <- sample_names(physeq.use)
colnames(keep) <- c("Sample", "Total_OTUs")
keep$Total_OTUs <- as.integer(keep$Total_OTUs)
adiv$Total_OTUs <- keep$Total_OTUs


# Color by group, facet by sample type
ggplot(otusum, aes(x=Group, y=Total_OTUs, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Group") +
  ylab("Total OTUs")

# Color by sample type, facet by group
ggplot(otusum, aes(x=Sample_Type, y=Total_OTUs, fill = Sample_Type)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Group) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Sample Type") +
  ylab("Total OTUs")


adiv.use.combos <- combn(x=levels(sampdf$Group), m=2)
adiv.pvals <- data.frame(rep(999,10))
for(i in 1:ncol(adiv.use.combos)){
  group1 <- which(adiv$Group == adiv.use.combos[1,i])
  group2 <- which(adiv$Group == adiv.use.combos[2,i])
  temp.df <- adiv[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv[group2,]
  test <- wilcox.test(Total_OTUs ~ Group, data=temp.df)
  adiv.pvals[i,1] <- test$p.value
  rownames(adiv.pvals)[i] <- paste(adiv.use.combos[1,i], adiv.use.combos[2,i])
}
colnames(adiv.pvals) <- "otusum.pval"
adiv.pvals$otusum.bonf <- p.adjust(adiv.pvals$otusum.pval, method="bonferroni")
adiv.pvals$otusum.BH <- p.adjust(adiv.pvals$otusum.pval, method="BH")

for(i in 1:ncol(adiv.use.combos)){
  group1 <- which(adiv$Group == adiv.use.combos[1,i])
  group2 <- which(adiv$Group == adiv.use.combos[2,i])
  temp.df <- adiv[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv[group2,]
  test <- wilcox.test(chao ~ Group, data=temp.df)
  adiv.pvals[i,4] <- test$p.value
}
colnames(adiv.pvals)[4] <- "chao.pval"
adiv.pvals$chao.bonf <- p.adjust(adiv.pvals$chao.pval, method="bonferroni")
adiv.pvals$chao.BH <- p.adjust(adiv.pvals$chao.pval, method="BH")

for(i in 1:ncol(adiv.use.combos)){
  group1 <- which(adiv$Group == adiv.use.combos[1,i])
  group2 <- which(adiv$Group == adiv.use.combos[2,i])
  temp.df <- adiv[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv[group2,]
  test <- wilcox.test(bergerparker ~ Group, data=temp.df)
  adiv.pvals[i,7] <- test$p.value
}
colnames(adiv.pvals)[7] <- "bp.pval"
adiv.pvals$bp.bonf <- p.adjust(adiv.pvals$bp.pval, method="bonferroni")
adiv.pvals$bp.BH <- p.adjust(adiv.pvals$bp.pval, method="BH")

aov.shannon.group <- aov(shannon ~ Group, data=adiv)
tukey.shannon <- TukeyHSD(aov.shannon.group)
adiv.pvals$shannon.tukey.pval<-tukey.shannon$Group[,4]

           
for(i in 1:ncol(adiv.use.combos)){
  group1 <- which(adiv$Group == adiv.use.combos[1,i])
  group2 <- which(adiv$Group == adiv.use.combos[2,i])
  temp.df <- adiv[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv[group2,]
  test <- wilcox.test(invsimpson ~ Group, data=temp.df)
  adiv.pvals[i,11] <- test$p.value
}
colnames(adiv.pvals)[11] <- "invsimp.pval"
adiv.pvals$invsimp.bonf <- p.adjust(adiv.pvals$invsimp.pval, method="bonferroni")
adiv.pvals$invsimp.BH <- p.adjust(adiv.pvals$invsimp.pval, method="BH")






adiv.con <- adiv[which(adiv$Sample_Type=="Content"),]
adiv.con.pvals <- data.frame(rep(999,10))
for(i in 1:ncol(adiv.use.combos)){
  group1 <- which(adiv.con$Group == adiv.use.combos[1,i])
  group2 <- which(adiv.con$Group == adiv.use.combos[2,i])
  temp.df <- adiv.con[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.con[group2,]
  test <- wilcox.test(Total_OTUs ~ Group, data=temp.df)
  adiv.con.pvals[i,1] <- test$p.value
  rownames(adiv.con.pvals)[i] <- paste(adiv.use.combos[1,i], adiv.use.combos[2,i])
}
colnames(adiv.con.pvals) <- "otusum.pval"
adiv.con.pvals$otusum.bonf <- p.adjust(adiv.con.pvals$otusum.pval, method="bonferroni")
adiv.con.pvals$otusum.BH <- p.adjust(adiv.con.pvals$otusum.pval, method="BH")

for(i in 1:ncol(adiv.use.combos)){
  group1 <- which(adiv.con$Group == adiv.use.combos[1,i])
  group2 <- which(adiv.con$Group == adiv.use.combos[2,i])
  temp.df <- adiv.con[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.con[group2,]
  test <- wilcox.test(chao ~ Group, data=temp.df)
  adiv.con.pvals[i,4] <- test$p.value
}
colnames(adiv.con.pvals)[4] <- "chao.pval"
adiv.con.pvals$chao.bonf <- p.adjust(adiv.con.pvals$chao.pval, method="bonferroni")
adiv.con.pvals$chao.BH <- p.adjust(adiv.con.pvals$chao.pval, method="BH")

for(i in 1:ncol(adiv.use.combos)){
  group1 <- which(adiv.con$Group == adiv.use.combos[1,i])
  group2 <- which(adiv.con$Group == adiv.use.combos[2,i])
  temp.df <- adiv.con[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.con[group2,]
  test <- wilcox.test(bergerparker ~ Group, data=temp.df)
  adiv.con.pvals[i,7] <- test$p.value
}
colnames(adiv.con.pvals)[7] <- "bp.pval"
adiv.con.pvals$bp.bonf <- p.adjust(adiv.con.pvals$bp.pval, method="bonferroni")
adiv.con.pvals$bp.BH <- p.adjust(adiv.con.pvals$bp.pval, method="BH")

aov.shannon.group <- aov(shannon ~ Group, data=adiv.con)
tukey.shannon <- TukeyHSD(aov.shannon.group)
adiv.con.pvals$shannon.tukey.pval<-tukey.shannon$Group[,4]

           
for(i in 1:ncol(adiv.use.combos)){
  group1 <- which(adiv.con$Group == adiv.use.combos[1,i])
  group2 <- which(adiv.con$Group == adiv.use.combos[2,i])
  temp.df <- adiv.con[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.con[group2,]
  test <- wilcox.test(invsimpson ~ Group, data=temp.df)
  adiv.con.pvals[i,11] <- test$p.value
}
colnames(adiv.con.pvals)[11] <- "invsimp.pval"
adiv.con.pvals$invsimp.bonf <- p.adjust(adiv.con.pvals$invsimp.pval, method="bonferroni")
adiv.con.pvals$invsimp.BH <- p.adjust(adiv.con.pvals$invsimp.pval, method="BH")








adiv.muc <- adiv[which(adiv$Sample_Type=="Content"),]
adiv.muc.pvals <- data.frame(rep(999,10))
for(i in 1:ncol(adiv.use.combos)){
  group1 <- which(adiv.muc$Group == adiv.use.combos[1,i])
  group2 <- which(adiv.muc$Group == adiv.use.combos[2,i])
  temp.df <- adiv.muc[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.muc[group2,]
  test <- wilcox.test(Total_OTUs ~ Group, data=temp.df)
  adiv.muc.pvals[i,1] <- test$p.value
  rownames(adiv.muc.pvals)[i] <- paste(adiv.use.combos[1,i], adiv.use.combos[2,i])
}
colnames(adiv.muc.pvals) <- "otusum.pval"
adiv.muc.pvals$otusum.bonf <- p.adjust(adiv.muc.pvals$otusum.pval, method="bonferroni")
adiv.muc.pvals$otusum.BH <- p.adjust(adiv.muc.pvals$otusum.pval, method="BH")

for(i in 1:ncol(adiv.use.combos)){
  group1 <- which(adiv.muc$Group == adiv.use.combos[1,i])
  group2 <- which(adiv.muc$Group == adiv.use.combos[2,i])
  temp.df <- adiv.muc[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.muc[group2,]
  test <- wilcox.test(chao ~ Group, data=temp.df)
  adiv.muc.pvals[i,4] <- test$p.value
}
colnames(adiv.muc.pvals)[4] <- "chao.pval"
adiv.muc.pvals$chao.bonf <- p.adjust(adiv.muc.pvals$chao.pval, method="bonferroni")
adiv.muc.pvals$chao.BH <- p.adjust(adiv.muc.pvals$chao.pval, method="BH")

for(i in 1:ncol(adiv.use.combos)){
  group1 <- which(adiv.muc$Group == adiv.use.combos[1,i])
  group2 <- which(adiv.muc$Group == adiv.use.combos[2,i])
  temp.df <- adiv.muc[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.muc[group2,]
  test <- wilcox.test(bergerparker ~ Group, data=temp.df)
  adiv.muc.pvals[i,7] <- test$p.value
}
colnames(adiv.muc.pvals)[7] <- "bp.pval"
adiv.muc.pvals$bp.bonf <- p.adjust(adiv.muc.pvals$bp.pval, method="bonferroni")
adiv.muc.pvals$bp.BH <- p.adjust(adiv.muc.pvals$bp.pval, method="BH")

aov.shannon.group <- aov(shannon ~ Group, data=adiv.muc)
tukey.shannon <- TukeyHSD(aov.shannon.group)
adiv.muc.pvals$shannon.tukey.pval<-tukey.shannon$Group[,4]

           
for(i in 1:ncol(adiv.use.combos)){
  group1 <- which(adiv.muc$Group == adiv.use.combos[1,i])
  group2 <- which(adiv.muc$Group == adiv.use.combos[2,i])
  temp.df <- adiv.muc[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.muc[group2,]
  test <- wilcox.test(invsimpson ~ Group, data=temp.df)
  adiv.muc.pvals[i,11] <- test$p.value
}
colnames(adiv.muc.pvals)[11] <- "invsimp.pval"
adiv.muc.pvals$invsimp.bonf <- p.adjust(adiv.muc.pvals$invsimp.pval, method="bonferroni")
adiv.muc.pvals$invsimp.BH <- p.adjust(adiv.muc.pvals$invsimp.pval, method="BH")




# group.combos <- data.frame(rep("blah", 10))
# for(i in 1:ncol(adiv.use.combos)){
#   rownames(group.combos)[i] <- paste(adiv.use.combos[1,i], adiv.use.combos[2,i])
#   group.combos[i,1] <- rownames(group.combos)[i]
# }
# all.combos <- data.frame(rep("NA",20))
# all.combos[,1] <- rep(rownames(group.combos),2)
# all.combos[,2] <- c(rep("Content", 10), rep("Mucosa",10))
# all.combos[,3] <- paste(all.combos[,1], all.combos[,2])



adiv.use.all.combos <- combn(x=levels(s))
bray.pvals <- data.frame(rep(999,10))
for( i in 1:ncol(combos)){
  temp.physeq <- subset_samples(physeq.use, Group%in% combos[,i])
  temp.sampdf <- data.frame(sample_data(temp.physeq))
  temp.bray <- phyloseq::distance(physeq=temp.physeq, method="bray")
  test <- adonis(temp.bray ~ Group, data=temp.sampdf)
  rownames(bray.pvals)[i] <- paste(combos[1,i], combos[2,i])
  bray.pvals[i,1]<- test[[1]]$`Pr(>F)`[1]
}
colnames(bray.pvals) <- "pval"
bray.pvals$Adj.bonf <- p.adjust(bray.pvals$pval, method="bonferroni")
bray.pvals$Adj.BH <- p.adjust(bray.pvals$pval, method="BH")









# Color by group
ggplot(otusum, aes(x=Group, y=Total_OTUs, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  #facet_grid(.~Sample_Type) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Group") +
  ylab("Total OTUs")



# Test normality
hist(otusum$Total_OTUs, breaks=10)
qqnorm(otusum$Total_OTUs)
qqline(otusum$Total_OTUs)
shapiro.test(otusum$Total_OTUs)
  # p-value = 1.276e-06
  # p-value = 3.505e-07
ks.test(otusum$Total_OTUs, "pnorm", mean=mean(otusum$Total_OTUs), sd=sd(otusum$Total_OTUs))
  # p-value = 0.01574
  # p-value = 0.0112

# Kruskal-Wallis
kruskal.test(formula = Total_OTUs ~ Group, data = otusum)
  # p-value = 7.987e-05
  # p-value = 8.832e-06
kruskalmc(resp = Total_OTUs ~ Group, data = otusum)
  # Significant:
    # Summer_Wild-Torpor
    # Summer_Wild-IBA
    # Summer_Lab-IBA
kruskal.test(formula = Total_OTUs ~ Group, data = otusum, subset=Diet=="Lab")
  # p-value = 0.004659
  # p-value = 0.004648
kruskal.test(formula = Total_OTUs ~ Sample_Type, data = otusum)
  # p-value = 0.4302
  # p-value = 0.4259
kruskal.test(formula = Total_OTUs ~ Diet, data = otusum)
  # p-value = 8.811e-05
  # p-value = 9.359e-05
kruskal.test(formula = Total_OTUs ~ Diet, data = otusum, subset=Season=="Summer")
  # p-value = 0.009111
wilcox.test(Total_OTUs ~ Diet, data=otusum)
  # p-value = 0.0001003

### Chao
# Color by group
ggplot(adiv, aes(x=Group, y=chao, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  #facet_grid(.~Substrate) +
  #scale_fill_manual(values=c("gray95", "dimgray") )+
  xlab("Group") +
  ylab("Chao Richness")
# Color by group, facet by sample type
ggplot(adiv, aes(x=Group, y=chao, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Group") +
  ylab("Chao Richness")

# Test normality
hist(adiv$chao, breaks=10)
qqnorm(adiv$chao)
qqline(adiv$chao)
shapiro.test(adiv$chao)
  # p-value = 1.736e-05
  # p-value = 3.96e-05
ks.test(adiv$chao, "pnorm", mean=mean(adiv$chao), sd=sd(adiv$chao))
  # p-value = 0.2134
  # p-value = 0.335

# Kruskal-Wallis
kruskal.test(formula = chao ~ Group, data = adiv)
  # p-value = 0.02779
  # p-value = 0.01146
kruskalmc(resp = chao ~ Group, data = adiv)
  # Significant:
    # Summer-Spring
kruskal.test(formula = chao ~ Group, data = adiv, subset=Diet=="Lab")
  # p-value = 0.119
  # p-value = 0.1177
kruskal.test(formula = chao ~ Sample_Type, data = adiv)
  # p-value = 0.1792
  # p-value = 0.2279
kruskal.test(formula = chao ~ Diet, data = adiv)
  # p-value = 0.004116
kruskal.test(formula = chao ~ Diet, data = adiv, subset=Season=="Summer")
  # p-value = 0.0208
wilcox.test(chao ~ Diet, data=adiv)
  # p-value = 0.002454


### Berger-Parker
# Color by group
ggplot(adiv, aes(x=Group, y=bergerparker, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  #facet_grid(.~Substrate) +
  #scale_fill_manual(values=c("gray95", "dimgray") )+
  xlab("Group") +
  ylab("Berger-Parker")
# Color by group, facet by sample type
ggplot(adiv, aes(x=Group, y=bergerparker, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  #scale_fill_manual(values=c("gray95", "dimgray") )+
  xlab("Group") +
  ylab("Berger-Parker")

# Test normality
hist(adiv$bergerparker, breaks=10)
qqnorm(adiv$bergerparker)
qqline(adiv$bergerparker)
shapiro.test(adiv$bergerparker)
  # p-value = 2.924e-05
ks.test(adiv$bergerparker, "pnorm", mean=mean(adiv$bergerparker), sd=sd(adiv$bergerparker))
  # p-value = 0.351

# Kruskal-Wallis
kruskal.test(formula = bergerparker ~ Group, data = adiv)
  # p-value = 0.4087
kruskal.test(formula = bergerparker ~ Group, data = adiv, subset=Diet=="Lab")
  # p-value = 0.7487
kruskal.test(formula = bergerparker ~ Sample_Type, data = adiv)
  # p-value = 0.594
kruskal.test(formula = bergerparker ~ Diet, data = adiv)
  # p-value = 0.03825
kruskal.test(formula = bergerparker ~ Diet, data = adiv, subset=Season=="Summer")
  # p-value = 0.1317
wilcox.test(bergerparker ~ Diet, data=adiv)
  # p-value = 0.03743


### Shannon
# Color by group
ggplot(adiv, aes(x=Group, y=shannon, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  #facet_grid(.~Substrate) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Group") +
  ylab("Shannon Diversity")
# Color by group, facet by sample type
ggplot(adiv, aes(x=Group, y=shannon, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Group") +
  ylab("Shannon Diversity")

# Test normality
hist(adiv$shannon, breaks=10)
qqnorm(adiv$shannon)
qqline(adiv$shannon)
shapiro.test(adiv$shannon)
  # p-value = 0.3431
ks.test(adiv$shannon, "pnorm", mean=mean(adiv$shannon), sd=sd(adiv$shannon))
  # p-value = 0.9152

# ANOVA
summary(aov(shannon ~ Group, data=adiv))
  # p-value = 0.0501
t.test(shannon ~ Sample_Type, data=adiv)
  # p-value = 0.8445
t.test(shannon ~ Diet, data=adiv)
  # p-value = 0.02371



### Inverse Simpson
# Color by group
ggplot(adiv, aes(x=Group, y= invsimpson, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  #facet_grid(.~Substrate) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Group") +
  ylab("Inverse Simpson Diversity")
# Color by group, facet by sample type
ggplot(adiv, aes(x=Group, y= invsimpson, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Group") +
  ylab("Inverse Simpson Diversity")

# Test normality
hist(adiv$invsimpson, breaks=10)
qqnorm(adiv$invsimpson)
qqline(adiv$invsimpson)
shapiro.test(adiv$invsimpson)
  # p-value = 6.667e-06
ks.test(adiv$invsimpson, "pnorm", mean=mean(adiv$invsimpson), sd=sd(adiv$invsimpson))
  # p-value = 0.02063

# Kruskal-Wallis
kruskal.test(formula = invsimpson ~ Group, data = adiv)
  # p-value = 0.3059
kruskal.test(formula = invsimpson ~ Group, data = adiv, subset=Diet=="Lab")
  # p-value = 0.6151
kruskal.test(formula = invsimpson ~ Sample_Type, data = adiv)
  # p-value = 0.7817
kruskal.test(formula = invsimpson ~ Diet, data = adiv)
  # p-value = 0.02565
kruskal.test(formula = invsimpson ~ Diet, data = adiv, subset=Season=="Summer")
  # p-value = 0.08753
wilcox.test(invsimpson ~ Diet, data=adiv)
  # p-value = 0.0239













######### Beta Diversity #########

### Bray NMDS
nmds <- ordinate(physeq=physeq.use, method="NMDS", distance="bray")
  # Stress = 0.102554

plot_ordination(physeq=physeq.use, ordination=nmds, color="Group", shape="Sample_Type")


sample_data(physeq.use)$Elip <- paste(sample_data(physeq.use)$Group)
elip.nmds <- data.frame(MDS1 = nmds$points[,1], MDS2 = nmds$points[,2],
                        Group = sample_data(physeq.use)$Elip)
plot.new()
elip.ord <- ordiellipse(nmds, sample_data(physeq.use)$Elip, display="sites", kind="se", conf=0.95, label=T)

veganCovEllipse <- function(cov, center = c(0, 0), scale = 1, npoints = 100) {
    theta <- (0:npoints) * 2 * pi/npoints
    Circle <- cbind(cos(theta), sin(theta))
    t(center + scale * t(Circle %*% chol(cov)))
}

elip.df <- data.frame()
for(i in levels(elip.nmds$Group)){
  elip.df <- rbind(elip.df, cbind(as.data.frame(with(elip.nmds[elip.nmds$Group==i,],
                                                     veganCovEllipse(elip.ord[[i]]$cov,
                                                                     elip.ord[[i]]$center,
                                                                     elip.ord[[i]]$scale))),
                                  group=i))
  
}




plot_ordination(physeq=physeq.use, ordination=nmds, color="Group") +
  geom_path(data=elip.df, aes(x=NMDS1, y=NMDS2, colour=group), size=1, linetype=1) +
  guides(color=guide_legend(title="Group")) +
  scale_color_manual(values=c("brown2", "lightcoral", "royalblue3", "deepskyblue", "limegreen"))




### PERMANOVA
sampdf <- data.frame(sample_data(physeq.use))
bray<- phyloseq::distance(physeq=physeq.use, method="bray")
adonis(bray~ Group, data=sampdf)
  # p-value = 0.001
beta.tax = betadisper(d=bray, group=sampdf$Group)
p <- permutest(beta.tax)
p$tab
  # p-value = 0.026
adonis(bray~ Sample_Type, data=sampdf)
  # p-value = 1
beta.tax = betadisper(d=bray, group=sampdf$Sample_Type)
p <- permutest(beta.tax)
p$tab
  # p-value = 0.192

combos <- combn(x=levels(sampdf$Group), m=2)
bray.pvals <- data.frame(rep(999,10))
for( i in 1:ncol(combos)){
  temp.physeq <- subset_samples(physeq.use, Group%in% combos[,i])
  temp.sampdf <- data.frame(sample_data(temp.physeq))
  temp.bray <- phyloseq::distance(physeq=temp.physeq, method="bray")
  test <- adonis(temp.bray ~ Group, data=temp.sampdf)
  rownames(bray.pvals)[i] <- paste(combos[1,i], combos[2,i])
  bray.pvals[i,1]<- test[[1]]$`Pr(>F)`[1]
}
colnames(bray.pvals) <- "pval"
bray.pvals$Adj.bonf <- p.adjust(bray.pvals$pval, method="bonferroni")
bray.pvals$Adj.BH <- p.adjust(bray.pvals$pval, method="BH")
```


