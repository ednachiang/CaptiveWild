---
title: "Code"
author: "Edna Chiang"
date: "May 7, 2018"
output: html_document
---

### Load Libraries
```{r}
library(ape)
library(dplyr)
library(ggplot2)
library(gplots)
library(phangorn)
library(tidyr)
library(vegan)
library(phyloseq)
library(grid)
library(pgirmess)
theme_set(theme_bw())
set.seed(1)
```



### Import Data
```{r}
# Link files
shared = "mothur_output/final.shared"
taxonomy = "mothur_output/final.taxonomy"


# Import mothur data
mothurdata = import_mothur(
  mothur_shared_file = shared,
  mothur_constaxonomy_file = taxonomy)

# Add OTU column in taxonomy table
tax_table(mothurdata) <- cbind(tax_table(mothurdata), 
                               row.names(tax_table(mothurdata)))

# Rename taxonomy table columns
colnames(tax_table(mothurdata)) <- 
  c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus", "Species")
```

### Explore mothurdata object
```{r}
samp.sum <- data.frame(colSums(otu_table(mothurdata)))
colnames(samp.sum) <- "Sample_TotalSeqs"
samp.sum$sample <- row.names(samp.sum)
samp.sum <- arrange(samp.sum, Sample_TotalSeqs)

ggplot(samp.sum, aes(x=reorder(sample, Sample_TotalSeqs), y=Sample_TotalSeqs)) +
  ylab("Number of Sequences per Sample") +
  geom_bar(stat="identity", colour="black", fill="cornflowerblue") +
  xlab("Sample Name") +
  ggtitle("Total Number of Sequences per Sample") + 
  theme(axis.text.x = element_text(colour = "black", size=6, angle=45,hjust = 1,
                                   vjust = 1))

ggplot(data.frame(sum = sample_sums(mothurdata)), aes(sum)) + 
  geom_histogram(colour = "white", fill = "blue", bins=60) + 
  ggtitle("Sample read counts") + 
  xlab("total sequences")


# Min, Mean, Max of sample read counts
min(sample_sums(mothurdata))
mean(sample_sums(mothurdata))
median(sample_sums(mothurdata))
max(sample_sums(mothurdata))
```


### Interim Phyloseq Object
```{r}
meta <- read.csv("metadata.csv")
colnames(meta)[1] <- "Sample"
rownames(meta) <- meta$Sample
divsum <- read.table("mothur_output/8494.summary", header=T)
remove <- setdiff(meta$Sample, divsum$group)
for(i in 1:length(remove)){
  meta <- meta[-which(meta$Sample == remove[i]),]
}


# Add in diversity summaries
meta[,11:21] <- divsum[,3:12]

# Create intermin phyloseq object
physeq <- merge_phyloseq(mothurdata, sample_data(meta))

# Order factors
sample_data(physeq)$Season <- ordered(sample_data(physeq)$Season,
                                     levels=c("Summer", "Winter", "Spring"))
sample_data(physeq)$Metabolism <- ordered(sample_data(physeq)$Metabolism,
                                     levels=c("Active", "Torpor", "IBA"))
sample_data(physeq)$Group <- ordered(sample_data(physeq)$Group,
                                     levels=c("Summer_Wild", "Summer_Lab", "Torpor", "IBA", "Spring"))

# Remove unwanted samples
physeq.rem <- subset_samples(physeq, Sample_Type != "Black_Tissue" & Season != "NA")



#save(physeq.rem, file="Physeq.RData")
```


### Load Phyloseq Object
```{r}
load("Physeq.RData")
```

### Examine Summer Lab vs. Wild
```{r}
sum.physeq <- subset_samples(physeq.rem, Season == "Summer")

###### Examine Phyla ######
# Merge samples with the same taxonomic rank
sum.goodphy <- tax_glom(sum.physeq, taxrank="Phylum")

# Transform each merged phylum count to rel abund
sum.phy99 <- transform_sample_counts(sum.goodphy, function(x){(x/sum(x))*100})

# Remove any phyla with <1% rel abund
sum.phy99 <- prune_taxa(taxa_sums(sum.phy99) > 1, sum.phy99)


# Summarize data
sum.phy.df <- psmelt(sum.phy99)
sum.phy.df$Phylum <- ordered(sum.phy.df$Phylum, levels=c("Firmicutes", "Bacteroidetes","Verrucomicrobia", "Proteobacteria", "Unclassified", "Cyanobacteria", "Tenericutes", "Elusimicrobia"))
sum.phy.df$Phylum[which(is.na(sum.phy.df$Phylum))] <- rep("Unclassified",18)
sum.phy.sum <- sum.phy.df %>%
  group_by(Diet, Sample_Type, Phylum) %>%
  summarize(Mean = mean(Abundance),
            Median = median(Abundance),
            SD = sd(Abundance),
            SE = (sd(Abundance)/(sqrt(length(Abundance)))),
            iqr = IQR(Abundance))

# Calculate IQR limits
sum.phy.sum$iqr.min <- sum.phy.sum$Median - 0.5*sum.phy.sum$iqr
sum.phy.sum[which(sum.phy.sum$iqr.min < 0),10] <- 0
  # Any IQR min < 0, change to 0 (otherwise error bar won't plot)
sum.phy.sum$iqr.max <- sum.phy.sum$Median + 0.5*sum.phy.sum$iqr


### Barplot ###
ggplot(sum.phy.sum, aes(x=Phylum, y=Median, fill=Phylum)) +
  geom_bar(stat="identity", color="black") +
  geom_errorbar(aes(ymax=iqr.max, ymin=iqr.min), width=0.25) +
  facet_grid(Diet ~ Sample_Type) +
  scale_fill_brewer(palette="Set1") +
  xlab("Phyla") +
  ylab("Median Relative Abundance for Phyla > 1%") +
  theme(axis.text.x = element_blank())


###### Alpha-Diversity ######
sum.adiv <- data.frame(sample_data(sum.physeq))

sum.adiv.con <- sum.adiv[which(sum.adiv$Sample_Type=="Content"),]
sum.adiv.muc <- sum.adiv[which(sum.adiv$Sample_Type=="Mucosa"),]
sum.adiv.lab <- sum.adiv[which(sum.adiv$Diet=="Lab"),]
sum.adiv.wil <- sum.adiv[which(sum.adiv$Diet=="Wild"),]

# Total OTUs
# Make the original, unnormalized phyloseq object

sum.otu.tot <- data.frame(sample_names(sum.physeq))
# Pull out # of OTUs from all samples
sum.otu.tot$Total_OTUs <- rep("NA", 17)
for(i in 1:17){
  sum.otu.tot[i,2] <- length(which(otu_table(sum.physeq)[,i] != 0))
}
colnames(sum.otu.tot) <- c("Sample", "Total_OTUs")
sum.otu.tot$Total_OTUs <- as.integer(sum.otu.tot$Total_OTUs)
sum.otusum <- sum.adiv
sum.otusum$Total_OTUs <- sum.otu.tot$Total_OTUs

# Color by group
ggplot(sum.otusum, aes(x=Diet, y=Total_OTUs, fill = Diet)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  scale_fill_manual(values=c("brown2", "lightcoral")) +
  xlab("Group") +
  ylab("Total OTUs")

# Test normality
hist(sum.otusum$Total_OTUs, breaks=10)
qqnorm(sum.otusum$Total_OTUs)
qqline(sum.otusum$Total_OTUs)
shapiro.test(sum.otusum$Total_OTUs)
  # p-value = 0.0071
  # Not normal
ks.test(sum.otusum$Total_OTUs, "pnorm", mean=mean(sum.otusum$Total_OTUs), sd=sd(sum.otusum$Total_OTUs))
  # p-value = 0.1352

# Wilcoxon
wilcox.test(Total_OTUs ~ Diet, data=sum.otusum)
  # p-value = 0.0001616
wilcox.test(Total_OTUs ~ Diet, data=sum.otusum, subset=Sample_Type=="Content")
  # p-value = 0.01667
wilcox.test(Total_OTUs ~ Diet, data=sum.otusum, subset=Sample_Type=="Mucosa")
  # p-value = 0.05714
wilcox.test(Total_OTUs ~ Sample_Type, data=sum.otusum)
  # p-value = 0.8868
wilcox.test(Total_OTUs ~ Sample_Type, data=sum.otusum, subset=Diet=="Lab")
  # p-value = 0.7879
wilcox.test(Total_OTUs ~ Sample_Type, data=sum.otusum, subset=Diet=="Wild")
  # p-value = 1




### Chao
ggplot(sum.adiv, aes(x=Diet, y=chao, fill = Diet)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  scale_fill_manual(values=c("brown2", "lightcoral") )+
  xlab("Diet") +
  ylab("Chao Richness")

# Test normality
hist(sum.adiv$chao, breaks=10)
qqnorm(sum.adiv$chao)
qqline(sum.adiv$chao)
shapiro.test(sum.adiv$chao)
  # p-value = 0.01554
  # Not normal
ks.test(sum.adiv$chao, "pnorm", mean=mean(sum.adiv$chao), sd=sd(sum.adiv$chao))
  # p-value = 0.6185

# Wilcoxon
wilcox.test(chao ~ Diet, data=sum.adiv)
  # p-value = 0.0202
wilcox.test(chao ~ Diet, data=sum.adiv, subset=Sample_Type=="Content")
  # p-value = 0.01667
wilcox.test(chao ~ Diet, data=sum.adiv, subset=Sample_Type=="Mucosa")
  # p-value = 0.8571
wilcox.test(chao ~ Sample_Type, data=sum.adiv)
  # p-value = 0.9623
wilcox.test(chao ~ Sample_Type, data=sum.adiv, subset=Diet=="Lab")
  # p-value = 0.7879
wilcox.test(chao ~ Sample_Type, data=sum.adiv, subset=Diet=="Wild")
  # p-value = 0.4






### Berger-Parker
ggplot(sum.adiv, aes(x=Diet, y=bergerparker, fill = Diet)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  scale_fill_manual(values=c("brown2", "lightcoral") )+
  xlab("Diet") +
  ylab("Berger-Parker")

# Test normality
hist(sum.adiv$bergerparker, breaks=10)
qqnorm(sum.adiv$bergerparker)
qqline(sum.adiv$bergerparker)
shapiro.test(sum.adiv$bergerparker)
  # p-value = 0.008697
ks.test(sum.adiv$bergerparker, "pnorm", mean=mean(sum.adiv$bergerparker), sd=sd(sum.adiv$bergerparker))
  # p-value = 0.4016

# Wilcoxon
wilcox.test(bergerparker ~ Diet, data=sum.adiv)
  # p-value = 0.149
wilcox.test(bergerparker ~ Diet, data=sum.adiv, subset=Sample_Type=="Content")
  # p-value = 0.03333
wilcox.test(bergerparker ~ Diet, data=sum.adiv, subset=Sample_Type=="Mucosa")
  # p-value = 0.8571
wilcox.test(bergerparker ~ Sample_Type, data=sum.adiv)
  # p-value = 0.9623
wilcox.test(bergerparker ~ Sample_Type, data=sum.adiv, subset=Diet=="Lab")
  # p-value = 0.6485
wilcox.test(bergerparker ~ Sample_Type, data=sum.adiv, subset=Diet=="Wild")
  # p-value = 0.4





### Shannon
ggplot(sum.adiv, aes(x=Diet, y=shannon, fill = Diet)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  scale_fill_manual(values=c("brown2", "lightcoral")) +
  xlab("Group") +
  ylab("Shannon Diversity")

# Test normality
hist(sum.adiv$shannon, breaks=10)
qqnorm(sum.adiv$shannon)
qqline(sum.adiv$shannon)
shapiro.test(sum.adiv$shannon)
  # p-value = 0.2649
ks.test(sum.adiv$shannon, "pnorm", mean=mean(sum.adiv$shannon), sd=sd(sum.adiv$shannon))
  # p-value = 0.6198

# Wilcoxon
t.test(shannon ~ Diet, data=sum.adiv)
  # p-value = 0.05814
t.test(shannon ~ Diet, data=sum.adiv.con)
  # p-value = 0.003129
t.test(shannon ~ Diet, data=sum.adiv.muc)
  # p-value = 0.9498
t.test(shannon ~ Sample_Type, data=sum.adiv)
  # p-value = 0.9695
t.test(shannon ~ Sample_Type, data=sum.adiv.lab)
  # p-value = 0.3654
t.test(shannon ~ Sample_Type, data=sum.adiv.wil)
  # p-value = 0.1508

# Inverse Simpson
ggplot(sum.adiv, aes(x=Diet, y= invsimpson, fill = Diet)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  scale_fill_manual(values=c("brown2", "lightcoral")) +
  xlab("Diet") +
  ylab("Inverse Simpson Diversity")

# Test normality
hist(sum.adiv$invsimpson, breaks=10)
qqnorm(sum.adiv$invsimpson)
qqline(sum.adiv$invsimpson)
shapiro.test(sum.adiv$invsimpson)
  # p-value = 0.01727
ks.test(sum.adiv$invsimpson, "pnorm", mean=mean(sum.adiv$invsimpson), sd=sd(sum.adiv$invsimpson))
  # p-value = 0.2989

# Wilcoxon
wilcox.test(invsimpson ~ Diet, data=sum.adiv)
  # p-value = 0.09825
wilcox.test(invsimpson ~ Diet, data=sum.adiv, subset=Sample_Type=="Content")
  # p-value = 0.01667
wilcox.test(invsimpson ~ Diet, data=sum.adiv, subset=Sample_Type=="Mucosa")
  # p-value = 0.8571
wilcox.test(invsimpson ~ Sample_Type, data=sum.adiv)
  # p-value = 0.8125
wilcox.test(invsimpson ~ Sample_Type, data=sum.adiv, subset=Diet=="Lab")
  # p-value = 0.6485
wilcox.test(invsimpson ~ Sample_Type, data=sum.adiv, subset=Diet=="Wild")
  # p-value = 0.2


###### Bray-Curtis ######
### Bray NMDS
sum.nmds <- ordinate(physeq=sum.physeq, method="NMDS", distance="bray")
  # stress = 0.07623348

plot_ordination(physeq=sum.physeq, ordination=sum.nmds, color="Diet", shape="Sample_Type")

# https://stackoverflow.com/questions/13794419/plotting-ordiellipse-function-from-vegan-package-onto-nmds-plot-created-in-ggplo

sample_data(sum.physeq)$Elip <- paste(sample_data(sum.physeq)$Diet, sample_data(sum.physeq)$Sample_Type)
elip.sum.nmds <- data.frame(MDS1 = sum.nmds$points[,1], MDS2 = sum.nmds$points[,2],
                        Group = sample_data(sum.physeq)$Elip)
plot.new()
elip.sum.ord <- ordiellipse(sum.nmds, sample_data(sum.physeq)$Elip, display="sites", kind="se", conf=0.95, label=T)

veganCovEllipse <- function(cov, center = c(0, 0), scale = 1, npoints = 100) {
    theta <- (0:npoints) * 2 * pi/npoints
    Circle <- cbind(cos(theta), sin(theta))
    t(center + scale * t(Circle %*% chol(cov)))
}

elip.sum.df <- data.frame()
for(i in levels(elip.sum.nmds$Group)){
  elip.sum.df <- rbind(elip.sum.df, cbind(as.data.frame(with(elip.sum.nmds[elip.sum.nmds$Group==i,],
                                                     veganCovEllipse(elip.sum.ord[[i]]$cov,
                                                                     elip.sum.ord[[i]]$center,
                                                                     elip.sum.ord[[i]]$scale))),
                                  group=i))
  
}




plot_ordination(physeq=sum.physeq, ordination=sum.nmds, color="Elip") +
  geom_path(data=elip.sum.df, aes(x=NMDS1, y=NMDS2, colour=group), size=1, linetype=1) +
  guides(color=guide_legend(title="Group")) +
  scale_color_manual(values=c("darkgoldenrod", "darkgoldenrod1", "brown2", "lightcoral"))



### PERMANOVA
sum.sampdf <- data.frame(sample_data(sum.physeq))
sum.bray<- phyloseq::distance(physeq=sum.physeq, method="bray")
adonis(sum.bray~ Diet, data=sum.sampdf)
  # p-value = 0.001
beta.tax = betadisper(d=sum.bray, group=sum.sampdf$Diet)
p <- permutest(beta.tax)
p$tab
  # p-value = 0.002
adonis(sum.bray~ Sample_Type, data=sum.sampdf)
  # p-value = 0.996
beta.tax = betadisper(d=sum.bray, group=sum.sampdf$Sample_Type)
p <- permutest(beta.tax)
p$tab
  # p-value = 0.656
```


### Alpha Div
```{r}
adiv <- data.frame(sample_data(physeq.rem))

par(mfrow=c(5,1))

# Coverage
ggplot(adiv, aes(x=Group, y= coverage, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  scale_fill_manual(values=c("brown2", "lightcoral", "royalblue3", "deepskyblue", "limegreen")) +
  xlab("Group") +
  ylab("Coverage")

# Total OTUs
# Make the original, unnormalized phyloseq object
shared = "mothur_output/final.shared"
taxonomy = "mothur_output/final.taxonomy"
mothurdata = import_mothur(
  mothur_shared_file = shared,
  mothur_constaxonomy_file = taxonomy)
tax_table(mothurdata) <- cbind(tax_table(mothurdata), 
                               row.names(tax_table(mothurdata)))
colnames(tax_table(mothurdata)) <- 
  c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus", "Species")
# Read in metadata
meta <- read.csv("metadata.csv")
colnames(meta)[1] <- "Sample"
otu.tot <- data.frame(sample_names(mothurdata))
# Pull out # of OTUs from all samples
otu.tot$Total_OTUs <- rep("NA", 77)
for(i in 1:77){
  otu.tot[i,2] <- length(which(otu_table(mothurdata)[,i] != 0))
}
# Pull out the data from just the samples we kept
keep <- data.frame(rep("NA",47))
keep[,2] <- rep("NA", 47)
for(i in 1:47){
  x <- which(otu.tot$sample_names.mothurdata. == sample_names(physeq.rem)[i])
  keep[i,2] <- otu.tot[x,2]
}
keep[,1] <- sample_names(physeq.rem)
colnames(keep) <- c("Sample", "Total_OTUs")
keep$Total_OTUs <- as.integer(keep$Total_OTUs)
adiv$Total_OTUs <- keep$Total_OTUs

# Color by group
ggplot(otusum, aes(x=Group, y=Total_OTUs, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  #facet_grid(.~Sample_Type) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Group") +
  ylab("Total OTUs")

# Color by group, facet by sample type
ggplot(otusum, aes(x=Group, y=Total_OTUs, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Group") +
  ylab("Total OTUs")

# Color by sample type, facet by group
ggplot(otusum, aes(x=Sample_Type, y=Total_OTUs, fill = Sample_Type)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Group) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Sample Type") +
  ylab("Total OTUs")

# Test normality
hist(otusum$Total_OTUs, breaks=10)
qqnorm(otusum$Total_OTUs)
qqline(otusum$Total_OTUs)
shapiro.test(otusum$Total_OTUs)
  # p-value = 1.276e-06
  # p-value = 3.505e-07
ks.test(otusum$Total_OTUs, "pnorm", mean=mean(otusum$Total_OTUs), sd=sd(otusum$Total_OTUs))
  # p-value = 0.01574
  # p-value = 0.0112

# Kruskal-Wallis
kruskal.test(formula = Total_OTUs ~ Group, data = otusum)
  # p-value = 7.987e-05
  # p-value = 8.832e-06
kruskalmc(resp = Total_OTUs ~ Group, data = otusum)
  # Significant:
    # Summer_Wild-Torpor
    # Summer_Wild-IBA
    # Summer_Lab-IBA
kruskal.test(formula = Total_OTUs ~ Group, data = otusum, subset=Diet=="Lab")
  # p-value = 0.004659
  # p-value = 0.004648
kruskal.test(formula = Total_OTUs ~ Sample_Type, data = otusum)
  # p-value = 0.4302
  # p-value = 0.4259
kruskal.test(formula = Total_OTUs ~ Diet, data = otusum)
  # p-value = 8.811e-05
  # p-value = 9.359e-05
kruskal.test(formula = Total_OTUs ~ Diet, data = otusum, subset=Season=="Summer")
  # p-value = 0.009111
wilcox.test(Total_OTUs ~ Diet, data=otusum)
  # p-value = 0.0001003

### Chao
# Color by group
ggplot(adiv, aes(x=Group, y=chao, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  #facet_grid(.~Substrate) +
  #scale_fill_manual(values=c("gray95", "dimgray") )+
  xlab("Group") +
  ylab("Chao Richness")
# Color by group, facet by sample type
ggplot(adiv, aes(x=Group, y=chao, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Group") +
  ylab("Chao Richness")

# Test normality
hist(adiv$chao, breaks=10)
qqnorm(adiv$chao)
qqline(adiv$chao)
shapiro.test(adiv$chao)
  # p-value = 1.736e-05
  # p-value = 3.96e-05
ks.test(adiv$chao, "pnorm", mean=mean(adiv$chao), sd=sd(adiv$chao))
  # p-value = 0.2134
  # p-value = 0.335

# Kruskal-Wallis
kruskal.test(formula = chao ~ Group, data = adiv)
  # p-value = 0.02779
  # p-value = 0.01146
kruskalmc(resp = chao ~ Group, data = adiv)
  # Significant:
    # Summer-Spring
kruskal.test(formula = chao ~ Group, data = adiv, subset=Diet=="Lab")
  # p-value = 0.119
  # p-value = 0.1177
kruskal.test(formula = chao ~ Sample_Type, data = adiv)
  # p-value = 0.1792
  # p-value = 0.2279
kruskal.test(formula = chao ~ Diet, data = adiv)
  # p-value = 0.004116
kruskal.test(formula = chao ~ Diet, data = adiv, subset=Season=="Summer")
  # p-value = 0.0208
wilcox.test(chao ~ Diet, data=adiv)
  # p-value = 0.002454


### Berger-Parker
# Color by group
ggplot(adiv, aes(x=Group, y=bergerparker, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  #facet_grid(.~Substrate) +
  #scale_fill_manual(values=c("gray95", "dimgray") )+
  xlab("Group") +
  ylab("Berger-Parker")
# Color by group, facet by sample type
ggplot(adiv, aes(x=Group, y=bergerparker, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  #scale_fill_manual(values=c("gray95", "dimgray") )+
  xlab("Group") +
  ylab("Berger-Parker")

# Test normality
hist(adiv$bergerparker, breaks=10)
qqnorm(adiv$bergerparker)
qqline(adiv$bergerparker)
shapiro.test(adiv$bergerparker)
  # p-value = 2.924e-05
ks.test(adiv$bergerparker, "pnorm", mean=mean(adiv$bergerparker), sd=sd(adiv$bergerparker))
  # p-value = 0.351

# Kruskal-Wallis
kruskal.test(formula = bergerparker ~ Group, data = adiv)
  # p-value = 0.4087
kruskal.test(formula = bergerparker ~ Group, data = adiv, subset=Diet=="Lab")
  # p-value = 0.7487
kruskal.test(formula = bergerparker ~ Sample_Type, data = adiv)
  # p-value = 0.594
kruskal.test(formula = bergerparker ~ Diet, data = adiv)
  # p-value = 0.03825
kruskal.test(formula = bergerparker ~ Diet, data = adiv, subset=Season=="Summer")
  # p-value = 0.1317
wilcox.test(bergerparker ~ Diet, data=adiv)
  # p-value = 0.03743


### Shannon
# Color by group
ggplot(adiv, aes(x=Group, y=shannon, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  #facet_grid(.~Substrate) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Group") +
  ylab("Shannon Diversity")
# Color by group, facet by sample type
ggplot(adiv, aes(x=Group, y=shannon, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Group") +
  ylab("Shannon Diversity")

# Test normality
hist(adiv$shannon, breaks=10)
qqnorm(adiv$shannon)
qqline(adiv$shannon)
shapiro.test(adiv$shannon)
  # p-value = 0.3431
ks.test(adiv$shannon, "pnorm", mean=mean(adiv$shannon), sd=sd(adiv$shannon))
  # p-value = 0.9152

# ANOVA
summary(aov(shannon ~ Group, data=adiv))
  # p-value = 0.0501
t.test(shannon ~ Sample_Type, data=adiv)
  # p-value = 0.8445
t.test(shannon ~ Diet, data=adiv)
  # p-value = 0.02371



### Inverse Simpson
# Color by group
ggplot(adiv, aes(x=Group, y= invsimpson, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  #facet_grid(.~Substrate) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Group") +
  ylab("Inverse Simpson Diversity")
# Color by group, facet by sample type
ggplot(adiv, aes(x=Group, y= invsimpson, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Group") +
  ylab("Inverse Simpson Diversity")

# Test normality
hist(adiv$invsimpson, breaks=10)
qqnorm(adiv$invsimpson)
qqline(adiv$invsimpson)
shapiro.test(adiv$invsimpson)
  # p-value = 6.667e-06
ks.test(adiv$invsimpson, "pnorm", mean=mean(adiv$invsimpson), sd=sd(adiv$invsimpson))
  # p-value = 0.02063

# Kruskal-Wallis
kruskal.test(formula = invsimpson ~ Group, data = adiv)
  # p-value = 0.3059
kruskal.test(formula = invsimpson ~ Group, data = adiv, subset=Diet=="Lab")
  # p-value = 0.6151
kruskal.test(formula = invsimpson ~ Sample_Type, data = adiv)
  # p-value = 0.7817
kruskal.test(formula = invsimpson ~ Diet, data = adiv)
  # p-value = 0.02565
kruskal.test(formula = invsimpson ~ Diet, data = adiv, subset=Season=="Summer")
  # p-value = 0.08753
wilcox.test(invsimpson ~ Diet, data=adiv)
  # p-value = 0.0239











adiv.rem.combos <- combn(x=levels(sampdf$Group), m=2)
adiv.pvals <- data.frame(rep(999,10))
for(i in 1:ncol(adiv.rem.combos)){
  group1 <- which(adiv$Group == adiv.rem.combos[1,i])
  group2 <- which(adiv$Group == adiv.rem.combos[2,i])
  temp.df <- adiv[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv[group2,]
  test <- wilcox.test(Total_OTUs ~ Group, data=temp.df)
  adiv.pvals[i,1] <- test$p.value
  rownames(adiv.pvals)[i] <- paste(adiv.rem.combos[1,i], adiv.rem.combos[2,i])
}
colnames(adiv.pvals) <- "otusum.pval"
adiv.pvals$otusum.bonf <- p.adjust(adiv.pvals$otusum.pval, method="bonferroni")
adiv.pvals$otusum.BH <- p.adjust(adiv.pvals$otusum.pval, method="BH")

for(i in 1:ncol(adiv.rem.combos)){
  group1 <- which(adiv$Group == adiv.rem.combos[1,i])
  group2 <- which(adiv$Group == adiv.rem.combos[2,i])
  temp.df <- adiv[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv[group2,]
  test <- wilcox.test(chao ~ Group, data=temp.df)
  adiv.pvals[i,4] <- test$p.value
}
colnames(adiv.pvals)[4] <- "chao.pval"
adiv.pvals$chao.bonf <- p.adjust(adiv.pvals$chao.pval, method="bonferroni")
adiv.pvals$chao.BH <- p.adjust(adiv.pvals$chao.pval, method="BH")

for(i in 1:ncol(adiv.rem.combos)){
  group1 <- which(adiv$Group == adiv.rem.combos[1,i])
  group2 <- which(adiv$Group == adiv.rem.combos[2,i])
  temp.df <- adiv[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv[group2,]
  test <- wilcox.test(bergerparker ~ Group, data=temp.df)
  adiv.pvals[i,7] <- test$p.value
}
colnames(adiv.pvals)[7] <- "bp.pval"
adiv.pvals$bp.bonf <- p.adjust(adiv.pvals$bp.pval, method="bonferroni")
adiv.pvals$bp.BH <- p.adjust(adiv.pvals$bp.pval, method="BH")

aov.shannon.group <- aov(shannon ~ Group, data=adiv)
tukey.shannon <- TukeyHSD(aov.shannon.group)
adiv.pvals$shannon.tukey.pval<-tukey.shannon$Group[,4]

           
for(i in 1:ncol(adiv.rem.combos)){
  group1 <- which(adiv$Group == adiv.rem.combos[1,i])
  group2 <- which(adiv$Group == adiv.rem.combos[2,i])
  temp.df <- adiv[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv[group2,]
  test <- wilcox.test(invsimpson ~ Group, data=temp.df)
  adiv.pvals[i,11] <- test$p.value
}
colnames(adiv.pvals)[11] <- "invsimp.pval"
adiv.pvals$invsimp.bonf <- p.adjust(adiv.pvals$invsimp.pval, method="bonferroni")
adiv.pvals$invsimp.BH <- p.adjust(adiv.pvals$invsimp.pval, method="BH")






adiv.con <- adiv[which(adiv$Sample_Type=="Content"),]
adiv.con.pvals <- data.frame(rep(999,10))
for(i in 1:ncol(adiv.rem.combos)){
  group1 <- which(adiv.con$Group == adiv.rem.combos[1,i])
  group2 <- which(adiv.con$Group == adiv.rem.combos[2,i])
  temp.df <- adiv.con[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.con[group2,]
  test <- wilcox.test(Total_OTUs ~ Group, data=temp.df)
  adiv.con.pvals[i,1] <- test$p.value
  rownames(adiv.con.pvals)[i] <- paste(adiv.rem.combos[1,i], adiv.rem.combos[2,i])
}
colnames(adiv.con.pvals) <- "otusum.pval"
adiv.con.pvals$otusum.bonf <- p.adjust(adiv.con.pvals$otusum.pval, method="bonferroni")
adiv.con.pvals$otusum.BH <- p.adjust(adiv.con.pvals$otusum.pval, method="BH")

for(i in 1:ncol(adiv.rem.combos)){
  group1 <- which(adiv.con$Group == adiv.rem.combos[1,i])
  group2 <- which(adiv.con$Group == adiv.rem.combos[2,i])
  temp.df <- adiv.con[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.con[group2,]
  test <- wilcox.test(chao ~ Group, data=temp.df)
  adiv.con.pvals[i,4] <- test$p.value
}
colnames(adiv.con.pvals)[4] <- "chao.pval"
adiv.con.pvals$chao.bonf <- p.adjust(adiv.con.pvals$chao.pval, method="bonferroni")
adiv.con.pvals$chao.BH <- p.adjust(adiv.con.pvals$chao.pval, method="BH")

for(i in 1:ncol(adiv.rem.combos)){
  group1 <- which(adiv.con$Group == adiv.rem.combos[1,i])
  group2 <- which(adiv.con$Group == adiv.rem.combos[2,i])
  temp.df <- adiv.con[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.con[group2,]
  test <- wilcox.test(bergerparker ~ Group, data=temp.df)
  adiv.con.pvals[i,7] <- test$p.value
}
colnames(adiv.con.pvals)[7] <- "bp.pval"
adiv.con.pvals$bp.bonf <- p.adjust(adiv.con.pvals$bp.pval, method="bonferroni")
adiv.con.pvals$bp.BH <- p.adjust(adiv.con.pvals$bp.pval, method="BH")

aov.shannon.group <- aov(shannon ~ Group, data=adiv.con)
tukey.shannon <- TukeyHSD(aov.shannon.group)
adiv.con.pvals$shannon.tukey.pval<-tukey.shannon$Group[,4]

           
for(i in 1:ncol(adiv.rem.combos)){
  group1 <- which(adiv.con$Group == adiv.rem.combos[1,i])
  group2 <- which(adiv.con$Group == adiv.rem.combos[2,i])
  temp.df <- adiv.con[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.con[group2,]
  test <- wilcox.test(invsimpson ~ Group, data=temp.df)
  adiv.con.pvals[i,11] <- test$p.value
}
colnames(adiv.con.pvals)[11] <- "invsimp.pval"
adiv.con.pvals$invsimp.bonf <- p.adjust(adiv.con.pvals$invsimp.pval, method="bonferroni")
adiv.con.pvals$invsimp.BH <- p.adjust(adiv.con.pvals$invsimp.pval, method="BH")








adiv.muc <- adiv[which(adiv$Sample_Type=="Content"),]
adiv.muc.pvals <- data.frame(rep(999,10))
for(i in 1:ncol(adiv.rem.combos)){
  group1 <- which(adiv.muc$Group == adiv.rem.combos[1,i])
  group2 <- which(adiv.muc$Group == adiv.rem.combos[2,i])
  temp.df <- adiv.muc[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.muc[group2,]
  test <- wilcox.test(Total_OTUs ~ Group, data=temp.df)
  adiv.muc.pvals[i,1] <- test$p.value
  rownames(adiv.muc.pvals)[i] <- paste(adiv.rem.combos[1,i], adiv.rem.combos[2,i])
}
colnames(adiv.muc.pvals) <- "otusum.pval"
adiv.muc.pvals$otusum.bonf <- p.adjust(adiv.muc.pvals$otusum.pval, method="bonferroni")
adiv.muc.pvals$otusum.BH <- p.adjust(adiv.muc.pvals$otusum.pval, method="BH")

for(i in 1:ncol(adiv.rem.combos)){
  group1 <- which(adiv.muc$Group == adiv.rem.combos[1,i])
  group2 <- which(adiv.muc$Group == adiv.rem.combos[2,i])
  temp.df <- adiv.muc[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.muc[group2,]
  test <- wilcox.test(chao ~ Group, data=temp.df)
  adiv.muc.pvals[i,4] <- test$p.value
}
colnames(adiv.muc.pvals)[4] <- "chao.pval"
adiv.muc.pvals$chao.bonf <- p.adjust(adiv.muc.pvals$chao.pval, method="bonferroni")
adiv.muc.pvals$chao.BH <- p.adjust(adiv.muc.pvals$chao.pval, method="BH")

for(i in 1:ncol(adiv.rem.combos)){
  group1 <- which(adiv.muc$Group == adiv.rem.combos[1,i])
  group2 <- which(adiv.muc$Group == adiv.rem.combos[2,i])
  temp.df <- adiv.muc[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.muc[group2,]
  test <- wilcox.test(bergerparker ~ Group, data=temp.df)
  adiv.muc.pvals[i,7] <- test$p.value
}
colnames(adiv.muc.pvals)[7] <- "bp.pval"
adiv.muc.pvals$bp.bonf <- p.adjust(adiv.muc.pvals$bp.pval, method="bonferroni")
adiv.muc.pvals$bp.BH <- p.adjust(adiv.muc.pvals$bp.pval, method="BH")

aov.shannon.group <- aov(shannon ~ Group, data=adiv.muc)
tukey.shannon <- TukeyHSD(aov.shannon.group)
adiv.muc.pvals$shannon.tukey.pval<-tukey.shannon$Group[,4]

           
for(i in 1:ncol(adiv.rem.combos)){
  group1 <- which(adiv.muc$Group == adiv.rem.combos[1,i])
  group2 <- which(adiv.muc$Group == adiv.rem.combos[2,i])
  temp.df <- adiv.muc[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.muc[group2,]
  test <- wilcox.test(invsimpson ~ Group, data=temp.df)
  adiv.muc.pvals[i,11] <- test$p.value
}
colnames(adiv.muc.pvals)[11] <- "invsimp.pval"
adiv.muc.pvals$invsimp.bonf <- p.adjust(adiv.muc.pvals$invsimp.pval, method="bonferroni")
adiv.muc.pvals$invsimp.BH <- p.adjust(adiv.muc.pvals$invsimp.pval, method="BH")

```


### Examine Phyla
```{r}
# Merge samples with the same taxonomic rank
goodphy <- tax_glom(physeq.use, taxrank="Phylum")

# Transform each merged phylum count to rel abund
phy99 <- transform_sample_counts(goodphy, function(x){(x/sum(x))*100})

# Remove any phyla with <1% rel abund
phy99 <- prune_taxa(taxa_sums(phy99) > 1, phy99)

# Create rank abundance of phyla
barplot(sort(taxa_sums(phy99),TRUE)[1:20]/nsamples(phy99),las=2,cex.axis=.7)

# Summarize data
phy.df <- psmelt(phy99)
phy.df$Phylum <- ordered(phy.df$Phylum, levels=c("Firmicutes", "Bacteroidetes","Verrucomicrobia", "Proteobacteria", "Unclassified", "Cyanobacteria", "Tenericutes", "Elusimicrobia"))
phy.df$Phylum[which(is.na(phy.df$Phylum))] <- rep("Unclassified",18)
phy.sum <- phy.df %>%
  group_by(Group, Sample_Type, Phylum) %>%
  summarize(Mean = mean(Abundance),
            Median = median(Abundance),
            SD = sd(Abundance),
            SE = (sd(Abundance)/(sqrt(length(Abundance)))),
            iqr = IQR(Abundance))

# Calculate IQR limits
phy.sum$iqr.min <- phy.sum$Median - 0.5*phy.sum$iqr
phy.sum[which(phy.sum$iqr.min < 0),10] <- 0
  # Any IQR min < 0, change to 0 (otherwise error bar won't plot)
phy.sum$iqr.max <- phy.sum$Median + 0.5*phy.sum$iqr


### Barplot ###
ggplot(phy.sum, aes(x=Phylum, y=Median, fill=Phylum)) +
  geom_bar(stat="identity", color="black") +
  geom_errorbar(aes(ymax=iqr.max, ymin=iqr.min), width=0.25) +
  facet_grid(Sample_Type ~ Group) +
  scale_fill_brewer(palette="Set1") +
  xlab("Phyla") +
  ylab("Median Relative Abundance for Phyla > 1%") +
  theme(axis.text.x = element_blank())

# Pull out otu table to test phyla
phy.num <- as.numeric(otu_table(phy99))

# Test normality
hist(phy.num, breaks=10)
qqnorm(phy.num)
qqline(phy.num)
shapiro.test(phy.num)
  # p-value < 2.2e-16
ks.test(phy.num, "pnorm", mean=mean(phy.num), sd=sd(phy.num))
  # p-value < 2.2e-16

# Get ready for stats
sampdf <- data.frame(sample_data(phy99))
sampdf$Relative_Abundance <- otu_table(phy99)
```




### Bray-Curtis Ordination
```{r}
### Bray NMDS
nmds <- ordinate(physeq=physeq.use, method="NMDS", distance="bray")
  # Stress = 0.102554

plot_ordination(physeq=physeq.use, ordination=nmds, color="Group", shape="Sample_Type")


sample_data(physeq.use)$Elip <- paste(sample_data(physeq.use)$Group)
elip.nmds <- data.frame(MDS1 = nmds$points[,1], MDS2 = nmds$points[,2],
                        Group = sample_data(physeq.use)$Elip)
plot.new()
elip.ord <- ordiellipse(nmds, sample_data(physeq.use)$Elip, display="sites", kind="se", conf=0.95, label=T)

veganCovEllipse <- function(cov, center = c(0, 0), scale = 1, npoints = 100) {
    theta <- (0:npoints) * 2 * pi/npoints
    Circle <- cbind(cos(theta), sin(theta))
    t(center + scale * t(Circle %*% chol(cov)))
}

elip.df <- data.frame()
for(i in levels(elip.nmds$Group)){
  elip.df <- rbind(elip.df, cbind(as.data.frame(with(elip.nmds[elip.nmds$Group==i,],
                                                     veganCovEllipse(elip.ord[[i]]$cov,
                                                                     elip.ord[[i]]$center,
                                                                     elip.ord[[i]]$scale))),
                                  group=i))
  
}




plot_ordination(physeq=physeq.use, ordination=nmds, color="Group") +
  geom_path(data=elip.df, aes(x=NMDS1, y=NMDS2, colour=group), size=1, linetype=1) +
  guides(color=guide_legend(title="Group")) +
  scale_color_manual(values=c("brown2", "lightcoral", "royalblue3", "deepskyblue", "limegreen"))


### PERMANOVA
sampdf <- data.frame(sample_data(physeq.use))
bray<- phyloseq::distance(physeq=physeq.use, method="bray")
adonis(bray~ Group, data=sampdf)
  # p-value = 0.001
beta.tax = betadisper(d=bray, group=sampdf$Group)
p <- permutest(beta.tax)
p$tab
  # p-value = 0.026
adonis(bray~ Sample_Type, data=sampdf)
  # p-value = 1
beta.tax = betadisper(d=bray, group=sampdf$Sample_Type)
p <- permutest(beta.tax)
p$tab
  # p-value = 0.192

combos <- combn(x=levels(sampdf$Group), m=2)
bray.pvals <- data.frame(rep(999,10))
for( i in 1:ncol(combos)){
  temp.physeq <- subset_samples(physeq.use, Group%in% combos[,i])
  temp.sampdf <- data.frame(sample_data(temp.physeq))
  temp.bray <- phyloseq::distance(physeq=temp.physeq, method="bray")
  test <- adonis(temp.bray ~ Group, data=temp.sampdf)
  rownames(bray.pvals)[i] <- paste(combos[1,i], combos[2,i])
  bray.pvals[i,1]<- test[[1]]$`Pr(>F)`[1]
}
colnames(bray.pvals) <- "pval"
bray.pvals$Adj.bonf <- p.adjust(bray.pvals$pval, method="bonferroni")
bray.pvals$Adj.BH <- p.adjust(bray.pvals$pval, method="BH")

sampdf2 <- data.frame(sample_data(physeq.rem))
combos2 <- combn(x=levels(sampdf2$Group), m=2)
bray.pvals2 <- data.frame(rep(999,10))
for( i in 1:ncol(combos2)){
  temp.physeq2 <- subset_samples(physeq.rem, Group%in% combos2[,i])
  temp.sampdf2 <- data.frame(sample_data(temp.physeq2))
  temp.bray2 <- phyloseq::distance(physeq=temp.physeq2, method="bray")
  test2 <- adonis(temp.bray2 ~ Group, data=temp.sampdf2)
  rownames(bray.pvals2)[i] <- paste(combos2[1,i], combos2[2,i])
  bray.pvals2[i,1]<- test2[[1]]$`Pr(>F)`[1]
}
colnames(bray.pvals2) <- "pval"
bray.pvals2$Adj.bonf <- p.adjust(bray.pvals2$pval, method="bonferroni")
bray.pvals2$Adj.BH <- p.adjust(bray.pvals2$pval, method="BH")



sampdf <- data.frame(sample_data(physeq.use))
bray<- phyloseq::distance(physeq=physeq.use, method="bray")
adonis(bray~ Group, data=sampdf)

#pulls out p-value:
  test[[1]]$`Pr(>F)`[1]
  #https://stackoverflow.com/questions/3366506/extract-p-value-from-aov?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa
```


### Cyanobacteria???
```{r}
cya <- subset_taxa(physeq.rem, Phylum == "Cyanobacteria")
cya.tax <- data.frame(tax_table(cya))
cya.rel <- transform_sample_counts(cya, function(x){(x/sum(x))*100})
cya.rel <- subset_samples(cya.rel, sample_names(cya.rel)!= "CC1_923_S")
cya.rel <- subset_samples(cya.rel, sample_names(cya.rel)!= "CC1_925_I")
cya.rel <- subset_samples(cya.rel, sample_names(cya.rel)!= "CM1_916_P")
cya.rel <- prune_taxa(taxa_sums(cya.rel)>0, cya.rel)
View(data.frame(otu_table(cya.rel)))
View(data.frame(tax_table(cya.rel)))
```




### Jaccard Ordination
```{r}
jac <- ordinate(physeq=physeq.use, method="NMDS", distance="jaccard")
  # stress =  0.1026393

plot_ordination(physeq=physeq.use, ordination=jac, color="Group", shape="Sample_Type")

# Try removing that insanely crazy Cellobiose ABX sample with all Proteos
physeq.use.rem <- subset_samples(physeq.use=physeq.use, sample_names(physeq.use) != "CC1_S25")
jac.rem <- ordinate(physeq.use=physeq.use.rem, method="NMDS", distance="jaccard")
  # Stress = 0.1032307 

plot_ordination(physeq.use=physeq.use.rem, ordination=jac.rem, color="ABX", shape="Substrate")
```








### Play with ellipses
```{r}
### Bray NMDS
# Try removing that insanely crazy Cellobiose ABX sample with all Proteos
physeq.use.rem <- subset_samples(physeq.use=physeq.use, sample_names(physeq.use) != "CC1_S25")
nmds.rem <- ordinate(physeq.use=physeq.use.rem, method="NMDS", distance="bray")
  # Stress = 0.1233697 

plot_ordination(physeq.use=physeq.use.rem, ordination=nmds.rem, color="ABX", shape="Substrate") +
  stat_ellipse(type = "norm", linetype = 2) + stat_ellipse(type = "t")


# https://stackoverflow.com/questions/13794419/plotting-ordiellipse-function-from-vegan-package-onto-nmds-plot-created-in-ggplo

elip.nmds <- data.frame(MDS1 = nmds.rem$points[,1], MDS2 = nmds.rem$points[,2],
                        ABX = sample_data(physeq.use.rem)$ABX)
plot.new()
elip.ord <- ordiellipse(nmds.rem, sample_data(physeq.use.rem)$ABX, display="sites", kind="se", conf=0.95, label=T)


veganCovEllipse <- function(cov, center = c(0, 0), scale = 1, npoints = 100) {
    theta <- (0:npoints) * 2 * pi/npoints
    Circle <- cbind(cos(theta), sin(theta))
    t(center + scale * t(Circle %*% chol(cov)))
}


elip.df <- data.frame()
for(i in levels(elip.nmds$ABX)){
  elip.df <- rbind(elip.df, cbind(as.data.frame(with(elip.nmds[elip.nmds$ABX==i,],
                                                     veganCovEllipse(elip.ord[[i]]$cov,
                                                                     elip.ord[[i]]$center,
                                                                     elip.ord[[i]]$scale))),
                                  group=i))
  
}


plot_ordination(physeq=physeq.use, ordination=nmds.rem, color="Group") +
  geom_path(data=elip.df, aes(x=NMDS1, y=NMDS2, colour=group), size=1, linetype=1) +
  scale_color_manual(values=c("brown2", "lightcoral", "royalblue3", "deepskyblue", "limegreen"))

```



### Remove 3916 outlier
```{r}
### TLDR: Removing it doesn't make a very large difference-- certainly not the diff btwn sig vs. not sig
# Squirrel 916 (Spring) is an outlier
  # Both content & mucosa is WAY LESS DIVERSE tan everything else
# 3916 metadata:
  # Weight to warm = 97
    # Normal = >110
  # Weight at sacrifice = 122
    # Normal = >145
  # Sacrifice body temp = 34
    # Normal = ~37

### New phyloseq object
physeq.use <- subset_samples(physeq=physeq.rem, sample_data(physeq.rem)$ID != 3916)

######### Alpha Diversity #########

adiv <- data.frame(sample_data(physeq.use))

### Total OTUs ###
shared = "mothur_output/final.shared"
taxonomy = "mothur_output/final.taxonomy"
mothurdata = import_mothur(
  mothur_shared_file = shared,
  mothur_constaxonomy_file = taxonomy)
tax_table(mothurdata) <- cbind(tax_table(mothurdata), 
                               row.names(tax_table(mothurdata)))
colnames(tax_table(mothurdata)) <- 
  c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus", "Species")
# Read in metadata
meta <- read.csv("metadata.csv")
colnames(meta)[1] <- "Sample"
otu.tot <- data.frame(sample_names(mothurdata))
# Pull out # of OTUs from all samples
otu.tot$Total_OTUs <- rep("NA", 77)
for(i in 1:77){
  otu.tot[i,2] <- length(which(otu_table(mothurdata)[,i] != 0))
}
# Pull out the data from just the samples we kept
keep <- data.frame(rep("NA",45))
keep[,2] <- rep("NA", 45)
for(i in 1:45){
  x <- which(otu.tot$sample_names.mothurdata. == sample_names(physeq.use)[i])
  keep[i,2] <- otu.tot[x,2]
}
keep[,1] <- sample_names(physeq.use)
colnames(keep) <- c("Sample", "Total_OTUs")
keep$Total_OTUs <- as.integer(keep$Total_OTUs)
adiv$Total_OTUs <- keep$Total_OTUs


# Color by group, facet by sample type
ggplot(otusum, aes(x=Group, y=Total_OTUs, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Group") +
  ylab("Total OTUs")

# Color by sample type, facet by group
ggplot(otusum, aes(x=Sample_Type, y=Total_OTUs, fill = Sample_Type)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Group) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Sample Type") +
  ylab("Total OTUs")


adiv.use.combos <- combn(x=levels(sampdf$Group), m=2)
adiv.pvals <- data.frame(rep(999,10))
for(i in 1:ncol(adiv.use.combos)){
  group1 <- which(adiv$Group == adiv.use.combos[1,i])
  group2 <- which(adiv$Group == adiv.use.combos[2,i])
  temp.df <- adiv[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv[group2,]
  test <- wilcox.test(Total_OTUs ~ Group, data=temp.df)
  adiv.pvals[i,1] <- test$p.value
  rownames(adiv.pvals)[i] <- paste(adiv.use.combos[1,i], adiv.use.combos[2,i])
}
colnames(adiv.pvals) <- "otusum.pval"
adiv.pvals$otusum.bonf <- p.adjust(adiv.pvals$otusum.pval, method="bonferroni")
adiv.pvals$otusum.BH <- p.adjust(adiv.pvals$otusum.pval, method="BH")

for(i in 1:ncol(adiv.use.combos)){
  group1 <- which(adiv$Group == adiv.use.combos[1,i])
  group2 <- which(adiv$Group == adiv.use.combos[2,i])
  temp.df <- adiv[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv[group2,]
  test <- wilcox.test(chao ~ Group, data=temp.df)
  adiv.pvals[i,4] <- test$p.value
}
colnames(adiv.pvals)[4] <- "chao.pval"
adiv.pvals$chao.bonf <- p.adjust(adiv.pvals$chao.pval, method="bonferroni")
adiv.pvals$chao.BH <- p.adjust(adiv.pvals$chao.pval, method="BH")

for(i in 1:ncol(adiv.use.combos)){
  group1 <- which(adiv$Group == adiv.use.combos[1,i])
  group2 <- which(adiv$Group == adiv.use.combos[2,i])
  temp.df <- adiv[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv[group2,]
  test <- wilcox.test(bergerparker ~ Group, data=temp.df)
  adiv.pvals[i,7] <- test$p.value
}
colnames(adiv.pvals)[7] <- "bp.pval"
adiv.pvals$bp.bonf <- p.adjust(adiv.pvals$bp.pval, method="bonferroni")
adiv.pvals$bp.BH <- p.adjust(adiv.pvals$bp.pval, method="BH")

aov.shannon.group <- aov(shannon ~ Group, data=adiv)
tukey.shannon <- TukeyHSD(aov.shannon.group)
adiv.pvals$shannon.tukey.pval<-tukey.shannon$Group[,4]

           
for(i in 1:ncol(adiv.use.combos)){
  group1 <- which(adiv$Group == adiv.use.combos[1,i])
  group2 <- which(adiv$Group == adiv.use.combos[2,i])
  temp.df <- adiv[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv[group2,]
  test <- wilcox.test(invsimpson ~ Group, data=temp.df)
  adiv.pvals[i,11] <- test$p.value
}
colnames(adiv.pvals)[11] <- "invsimp.pval"
adiv.pvals$invsimp.bonf <- p.adjust(adiv.pvals$invsimp.pval, method="bonferroni")
adiv.pvals$invsimp.BH <- p.adjust(adiv.pvals$invsimp.pval, method="BH")






adiv.con <- adiv[which(adiv$Sample_Type=="Content"),]
adiv.con.pvals <- data.frame(rep(999,10))
for(i in 1:ncol(adiv.use.combos)){
  group1 <- which(adiv.con$Group == adiv.use.combos[1,i])
  group2 <- which(adiv.con$Group == adiv.use.combos[2,i])
  temp.df <- adiv.con[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.con[group2,]
  test <- wilcox.test(Total_OTUs ~ Group, data=temp.df)
  adiv.con.pvals[i,1] <- test$p.value
  rownames(adiv.con.pvals)[i] <- paste(adiv.use.combos[1,i], adiv.use.combos[2,i])
}
colnames(adiv.con.pvals) <- "otusum.pval"
adiv.con.pvals$otusum.bonf <- p.adjust(adiv.con.pvals$otusum.pval, method="bonferroni")
adiv.con.pvals$otusum.BH <- p.adjust(adiv.con.pvals$otusum.pval, method="BH")

for(i in 1:ncol(adiv.use.combos)){
  group1 <- which(adiv.con$Group == adiv.use.combos[1,i])
  group2 <- which(adiv.con$Group == adiv.use.combos[2,i])
  temp.df <- adiv.con[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.con[group2,]
  test <- wilcox.test(chao ~ Group, data=temp.df)
  adiv.con.pvals[i,4] <- test$p.value
}
colnames(adiv.con.pvals)[4] <- "chao.pval"
adiv.con.pvals$chao.bonf <- p.adjust(adiv.con.pvals$chao.pval, method="bonferroni")
adiv.con.pvals$chao.BH <- p.adjust(adiv.con.pvals$chao.pval, method="BH")

for(i in 1:ncol(adiv.use.combos)){
  group1 <- which(adiv.con$Group == adiv.use.combos[1,i])
  group2 <- which(adiv.con$Group == adiv.use.combos[2,i])
  temp.df <- adiv.con[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.con[group2,]
  test <- wilcox.test(bergerparker ~ Group, data=temp.df)
  adiv.con.pvals[i,7] <- test$p.value
}
colnames(adiv.con.pvals)[7] <- "bp.pval"
adiv.con.pvals$bp.bonf <- p.adjust(adiv.con.pvals$bp.pval, method="bonferroni")
adiv.con.pvals$bp.BH <- p.adjust(adiv.con.pvals$bp.pval, method="BH")

aov.shannon.group <- aov(shannon ~ Group, data=adiv.con)
tukey.shannon <- TukeyHSD(aov.shannon.group)
adiv.con.pvals$shannon.tukey.pval<-tukey.shannon$Group[,4]

           
for(i in 1:ncol(adiv.use.combos)){
  group1 <- which(adiv.con$Group == adiv.use.combos[1,i])
  group2 <- which(adiv.con$Group == adiv.use.combos[2,i])
  temp.df <- adiv.con[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.con[group2,]
  test <- wilcox.test(invsimpson ~ Group, data=temp.df)
  adiv.con.pvals[i,11] <- test$p.value
}
colnames(adiv.con.pvals)[11] <- "invsimp.pval"
adiv.con.pvals$invsimp.bonf <- p.adjust(adiv.con.pvals$invsimp.pval, method="bonferroni")
adiv.con.pvals$invsimp.BH <- p.adjust(adiv.con.pvals$invsimp.pval, method="BH")








adiv.muc <- adiv[which(adiv$Sample_Type=="Content"),]
adiv.muc.pvals <- data.frame(rep(999,10))
for(i in 1:ncol(adiv.use.combos)){
  group1 <- which(adiv.muc$Group == adiv.use.combos[1,i])
  group2 <- which(adiv.muc$Group == adiv.use.combos[2,i])
  temp.df <- adiv.muc[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.muc[group2,]
  test <- wilcox.test(Total_OTUs ~ Group, data=temp.df)
  adiv.muc.pvals[i,1] <- test$p.value
  rownames(adiv.muc.pvals)[i] <- paste(adiv.use.combos[1,i], adiv.use.combos[2,i])
}
colnames(adiv.muc.pvals) <- "otusum.pval"
adiv.muc.pvals$otusum.bonf <- p.adjust(adiv.muc.pvals$otusum.pval, method="bonferroni")
adiv.muc.pvals$otusum.BH <- p.adjust(adiv.muc.pvals$otusum.pval, method="BH")

for(i in 1:ncol(adiv.use.combos)){
  group1 <- which(adiv.muc$Group == adiv.use.combos[1,i])
  group2 <- which(adiv.muc$Group == adiv.use.combos[2,i])
  temp.df <- adiv.muc[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.muc[group2,]
  test <- wilcox.test(chao ~ Group, data=temp.df)
  adiv.muc.pvals[i,4] <- test$p.value
}
colnames(adiv.muc.pvals)[4] <- "chao.pval"
adiv.muc.pvals$chao.bonf <- p.adjust(adiv.muc.pvals$chao.pval, method="bonferroni")
adiv.muc.pvals$chao.BH <- p.adjust(adiv.muc.pvals$chao.pval, method="BH")

for(i in 1:ncol(adiv.use.combos)){
  group1 <- which(adiv.muc$Group == adiv.use.combos[1,i])
  group2 <- which(adiv.muc$Group == adiv.use.combos[2,i])
  temp.df <- adiv.muc[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.muc[group2,]
  test <- wilcox.test(bergerparker ~ Group, data=temp.df)
  adiv.muc.pvals[i,7] <- test$p.value
}
colnames(adiv.muc.pvals)[7] <- "bp.pval"
adiv.muc.pvals$bp.bonf <- p.adjust(adiv.muc.pvals$bp.pval, method="bonferroni")
adiv.muc.pvals$bp.BH <- p.adjust(adiv.muc.pvals$bp.pval, method="BH")

aov.shannon.group <- aov(shannon ~ Group, data=adiv.muc)
tukey.shannon <- TukeyHSD(aov.shannon.group)
adiv.muc.pvals$shannon.tukey.pval<-tukey.shannon$Group[,4]

           
for(i in 1:ncol(adiv.use.combos)){
  group1 <- which(adiv.muc$Group == adiv.use.combos[1,i])
  group2 <- which(adiv.muc$Group == adiv.use.combos[2,i])
  temp.df <- adiv.muc[group1,]
  temp.df[(nrow(temp.df)+1):(nrow(temp.df)+length(group2)),] <- adiv.muc[group2,]
  test <- wilcox.test(invsimpson ~ Group, data=temp.df)
  adiv.muc.pvals[i,11] <- test$p.value
}
colnames(adiv.muc.pvals)[11] <- "invsimp.pval"
adiv.muc.pvals$invsimp.bonf <- p.adjust(adiv.muc.pvals$invsimp.pval, method="bonferroni")
adiv.muc.pvals$invsimp.BH <- p.adjust(adiv.muc.pvals$invsimp.pval, method="BH")




# group.combos <- data.frame(rep("blah", 10))
# for(i in 1:ncol(adiv.use.combos)){
#   rownames(group.combos)[i] <- paste(adiv.use.combos[1,i], adiv.use.combos[2,i])
#   group.combos[i,1] <- rownames(group.combos)[i]
# }
# all.combos <- data.frame(rep("NA",20))
# all.combos[,1] <- rep(rownames(group.combos),2)
# all.combos[,2] <- c(rep("Content", 10), rep("Mucosa",10))
# all.combos[,3] <- paste(all.combos[,1], all.combos[,2])



adiv.use.all.combos <- combn(x=levels(s))
bray.pvals <- data.frame(rep(999,10))
for( i in 1:ncol(combos)){
  temp.physeq <- subset_samples(physeq.use, Group%in% combos[,i])
  temp.sampdf <- data.frame(sample_data(temp.physeq))
  temp.bray <- phyloseq::distance(physeq=temp.physeq, method="bray")
  test <- adonis(temp.bray ~ Group, data=temp.sampdf)
  rownames(bray.pvals)[i] <- paste(combos[1,i], combos[2,i])
  bray.pvals[i,1]<- test[[1]]$`Pr(>F)`[1]
}
colnames(bray.pvals) <- "pval"
bray.pvals$Adj.bonf <- p.adjust(bray.pvals$pval, method="bonferroni")
bray.pvals$Adj.BH <- p.adjust(bray.pvals$pval, method="BH")









# Color by group
ggplot(otusum, aes(x=Group, y=Total_OTUs, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  #facet_grid(.~Sample_Type) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Group") +
  ylab("Total OTUs")



# Test normality
hist(otusum$Total_OTUs, breaks=10)
qqnorm(otusum$Total_OTUs)
qqline(otusum$Total_OTUs)
shapiro.test(otusum$Total_OTUs)
  # p-value = 1.276e-06
  # p-value = 3.505e-07
ks.test(otusum$Total_OTUs, "pnorm", mean=mean(otusum$Total_OTUs), sd=sd(otusum$Total_OTUs))
  # p-value = 0.01574
  # p-value = 0.0112

# Kruskal-Wallis
kruskal.test(formula = Total_OTUs ~ Group, data = otusum)
  # p-value = 7.987e-05
  # p-value = 8.832e-06
kruskalmc(resp = Total_OTUs ~ Group, data = otusum)
  # Significant:
    # Summer_Wild-Torpor
    # Summer_Wild-IBA
    # Summer_Lab-IBA
kruskal.test(formula = Total_OTUs ~ Group, data = otusum, subset=Diet=="Lab")
  # p-value = 0.004659
  # p-value = 0.004648
kruskal.test(formula = Total_OTUs ~ Sample_Type, data = otusum)
  # p-value = 0.4302
  # p-value = 0.4259
kruskal.test(formula = Total_OTUs ~ Diet, data = otusum)
  # p-value = 8.811e-05
  # p-value = 9.359e-05
kruskal.test(formula = Total_OTUs ~ Diet, data = otusum, subset=Season=="Summer")
  # p-value = 0.009111
wilcox.test(Total_OTUs ~ Diet, data=otusum)
  # p-value = 0.0001003

### Chao
# Color by group
ggplot(adiv, aes(x=Group, y=chao, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  #facet_grid(.~Substrate) +
  #scale_fill_manual(values=c("gray95", "dimgray") )+
  xlab("Group") +
  ylab("Chao Richness")
# Color by group, facet by sample type
ggplot(adiv, aes(x=Group, y=chao, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Group") +
  ylab("Chao Richness")

# Test normality
hist(adiv$chao, breaks=10)
qqnorm(adiv$chao)
qqline(adiv$chao)
shapiro.test(adiv$chao)
  # p-value = 1.736e-05
  # p-value = 3.96e-05
ks.test(adiv$chao, "pnorm", mean=mean(adiv$chao), sd=sd(adiv$chao))
  # p-value = 0.2134
  # p-value = 0.335

# Kruskal-Wallis
kruskal.test(formula = chao ~ Group, data = adiv)
  # p-value = 0.02779
  # p-value = 0.01146
kruskalmc(resp = chao ~ Group, data = adiv)
  # Significant:
    # Summer-Spring
kruskal.test(formula = chao ~ Group, data = adiv, subset=Diet=="Lab")
  # p-value = 0.119
  # p-value = 0.1177
kruskal.test(formula = chao ~ Sample_Type, data = adiv)
  # p-value = 0.1792
  # p-value = 0.2279
kruskal.test(formula = chao ~ Diet, data = adiv)
  # p-value = 0.004116
kruskal.test(formula = chao ~ Diet, data = adiv, subset=Season=="Summer")
  # p-value = 0.0208
wilcox.test(chao ~ Diet, data=adiv)
  # p-value = 0.002454


### Berger-Parker
# Color by group
ggplot(adiv, aes(x=Group, y=bergerparker, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  #facet_grid(.~Substrate) +
  #scale_fill_manual(values=c("gray95", "dimgray") )+
  xlab("Group") +
  ylab("Berger-Parker")
# Color by group, facet by sample type
ggplot(adiv, aes(x=Group, y=bergerparker, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  #scale_fill_manual(values=c("gray95", "dimgray") )+
  xlab("Group") +
  ylab("Berger-Parker")

# Test normality
hist(adiv$bergerparker, breaks=10)
qqnorm(adiv$bergerparker)
qqline(adiv$bergerparker)
shapiro.test(adiv$bergerparker)
  # p-value = 2.924e-05
ks.test(adiv$bergerparker, "pnorm", mean=mean(adiv$bergerparker), sd=sd(adiv$bergerparker))
  # p-value = 0.351

# Kruskal-Wallis
kruskal.test(formula = bergerparker ~ Group, data = adiv)
  # p-value = 0.4087
kruskal.test(formula = bergerparker ~ Group, data = adiv, subset=Diet=="Lab")
  # p-value = 0.7487
kruskal.test(formula = bergerparker ~ Sample_Type, data = adiv)
  # p-value = 0.594
kruskal.test(formula = bergerparker ~ Diet, data = adiv)
  # p-value = 0.03825
kruskal.test(formula = bergerparker ~ Diet, data = adiv, subset=Season=="Summer")
  # p-value = 0.1317
wilcox.test(bergerparker ~ Diet, data=adiv)
  # p-value = 0.03743


### Shannon
# Color by group
ggplot(adiv, aes(x=Group, y=shannon, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  #facet_grid(.~Substrate) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Group") +
  ylab("Shannon Diversity")
# Color by group, facet by sample type
ggplot(adiv, aes(x=Group, y=shannon, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Group") +
  ylab("Shannon Diversity")

# Test normality
hist(adiv$shannon, breaks=10)
qqnorm(adiv$shannon)
qqline(adiv$shannon)
shapiro.test(adiv$shannon)
  # p-value = 0.3431
ks.test(adiv$shannon, "pnorm", mean=mean(adiv$shannon), sd=sd(adiv$shannon))
  # p-value = 0.9152

# ANOVA
summary(aov(shannon ~ Group, data=adiv))
  # p-value = 0.0501
t.test(shannon ~ Sample_Type, data=adiv)
  # p-value = 0.8445
t.test(shannon ~ Diet, data=adiv)
  # p-value = 0.02371



### Inverse Simpson
# Color by group
ggplot(adiv, aes(x=Group, y= invsimpson, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  #facet_grid(.~Substrate) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Group") +
  ylab("Inverse Simpson Diversity")
# Color by group, facet by sample type
ggplot(adiv, aes(x=Group, y= invsimpson, fill = Group)) +
  geom_boxplot(position=position_dodge(1)) +
  geom_point() + 
  facet_grid(.~Sample_Type) +
  #scale_fill_manual(values=c("gray95", "dimgray")) +
  xlab("Group") +
  ylab("Inverse Simpson Diversity")

# Test normality
hist(adiv$invsimpson, breaks=10)
qqnorm(adiv$invsimpson)
qqline(adiv$invsimpson)
shapiro.test(adiv$invsimpson)
  # p-value = 6.667e-06
ks.test(adiv$invsimpson, "pnorm", mean=mean(adiv$invsimpson), sd=sd(adiv$invsimpson))
  # p-value = 0.02063

# Kruskal-Wallis
kruskal.test(formula = invsimpson ~ Group, data = adiv)
  # p-value = 0.3059
kruskal.test(formula = invsimpson ~ Group, data = adiv, subset=Diet=="Lab")
  # p-value = 0.6151
kruskal.test(formula = invsimpson ~ Sample_Type, data = adiv)
  # p-value = 0.7817
kruskal.test(formula = invsimpson ~ Diet, data = adiv)
  # p-value = 0.02565
kruskal.test(formula = invsimpson ~ Diet, data = adiv, subset=Season=="Summer")
  # p-value = 0.08753
wilcox.test(invsimpson ~ Diet, data=adiv)
  # p-value = 0.0239













######### Beta Diversity #########

### Bray NMDS
nmds <- ordinate(physeq=physeq.use, method="NMDS", distance="bray")
  # Stress = 0.102554

plot_ordination(physeq=physeq.use, ordination=nmds, color="Group", shape="Sample_Type")


sample_data(physeq.use)$Elip <- paste(sample_data(physeq.use)$Group)
elip.nmds <- data.frame(MDS1 = nmds$points[,1], MDS2 = nmds$points[,2],
                        Group = sample_data(physeq.use)$Elip)
plot.new()
elip.ord <- ordiellipse(nmds, sample_data(physeq.use)$Elip, display="sites", kind="se", conf=0.95, label=T)

veganCovEllipse <- function(cov, center = c(0, 0), scale = 1, npoints = 100) {
    theta <- (0:npoints) * 2 * pi/npoints
    Circle <- cbind(cos(theta), sin(theta))
    t(center + scale * t(Circle %*% chol(cov)))
}

elip.df <- data.frame()
for(i in levels(elip.nmds$Group)){
  elip.df <- rbind(elip.df, cbind(as.data.frame(with(elip.nmds[elip.nmds$Group==i,],
                                                     veganCovEllipse(elip.ord[[i]]$cov,
                                                                     elip.ord[[i]]$center,
                                                                     elip.ord[[i]]$scale))),
                                  group=i))
  
}




plot_ordination(physeq=physeq.use, ordination=nmds, color="Group") +
  geom_path(data=elip.df, aes(x=NMDS1, y=NMDS2, colour=group), size=1, linetype=1) +
  guides(color=guide_legend(title="Group")) +
  scale_color_manual(values=c("brown2", "lightcoral", "royalblue3", "deepskyblue", "limegreen"))




### PERMANOVA
sampdf <- data.frame(sample_data(physeq.use))
bray<- phyloseq::distance(physeq=physeq.use, method="bray")
adonis(bray~ Group, data=sampdf)
  # p-value = 0.001
beta.tax = betadisper(d=bray, group=sampdf$Group)
p <- permutest(beta.tax)
p$tab
  # p-value = 0.026
adonis(bray~ Sample_Type, data=sampdf)
  # p-value = 1
beta.tax = betadisper(d=bray, group=sampdf$Sample_Type)
p <- permutest(beta.tax)
p$tab
  # p-value = 0.192

combos <- combn(x=levels(sampdf$Group), m=2)
bray.pvals <- data.frame(rep(999,10))
for( i in 1:ncol(combos)){
  temp.physeq <- subset_samples(physeq.use, Group%in% combos[,i])
  temp.sampdf <- data.frame(sample_data(temp.physeq))
  temp.bray <- phyloseq::distance(physeq=temp.physeq, method="bray")
  test <- adonis(temp.bray ~ Group, data=temp.sampdf)
  rownames(bray.pvals)[i] <- paste(combos[1,i], combos[2,i])
  bray.pvals[i,1]<- test[[1]]$`Pr(>F)`[1]
}
colnames(bray.pvals) <- "pval"
bray.pvals$Adj.bonf <- p.adjust(bray.pvals$pval, method="bonferroni")
bray.pvals$Adj.BH <- p.adjust(bray.pvals$pval, method="BH")
```


